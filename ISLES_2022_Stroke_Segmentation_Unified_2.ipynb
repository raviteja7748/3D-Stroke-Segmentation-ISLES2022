{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7591ea74",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "Cell 1: Environment, Imports & Mount"
   },
   "outputs": [],
   "source": [
    "# 3D Stroke Segmentation Pipeline - Refactored Production Version\n",
    "\n",
    "from __future__ import annotations\n",
    "import os, sys, torch, torch.nn as nn, torch.optim as optim, torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "import numpy as np, nibabel as nib\n",
    "from pathlib import Path\n",
    "import json, time, logging, random, warnings, shutil\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except ImportError:\n",
    "    def tqdm(iterable, desc=\"Progress\", **kwargs):\n",
    "        return iterable\n",
    "from scipy import ndimage\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "# CONSTANTS - Extracted magic numbers for better maintainability\n",
    "class Constants:\n",
    "    # Tversky Loss Parameters\n",
    "    TVERSKY_ALPHA = 0.25  # False positive penalty\n",
    "    TVERSKY_BETA = 0.85   # False negative penalty (higher for small lesions)\n",
    "    TVERSKY_GAMMA = 2.0   # Focal parameter\n",
    "    \n",
    "    # Training Thresholds\n",
    "    POSITIVE_RATIO = 0.7\n",
    "    \n",
    "    # Interpolation Orders\n",
    "    IMAGE_INTERPOLATION_ORDER = 3  # 3rd order spline\n",
    "    MASK_INTERPOLATION_ORDER = 1   # Linear for one-hot\n",
    "    NEAREST_INTERPOLATION_ORDER = 0  # Nearest neighbor fallback\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    COLAB_ENV = True\n",
    "except ImportError:\n",
    "    COLAB_ENV = False\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    torch.cuda.set_device(device)\n",
    "    torch.cuda.empty_cache()\n",
    "    logger.info(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    logger.warning(\"Using CPU - training will be slow\")\n",
    "\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.is_colab = COLAB_ENV\n",
    "        # Load folder config\n",
    "        if self.is_colab:\n",
    "            config_path = '/content/drive/MyDrive/stroke_segmentation_3d/folders_config.json'\n",
    "        else:\n",
    "            config_path = 'folders_config.json'\n",
    "            \n",
    "        with open(config_path, 'r') as f:\n",
    "            self.folder_names = json.load(f)\n",
    "        self._setup_paths()\n",
    "        self._setup_training()\n",
    "        self._setup_preprocessing_config()\n",
    "        \n",
    "    def _setup_paths(self):\n",
    "        # Auto-detect base path\n",
    "        if self.is_colab:\n",
    "            possible_bases = [Path(\"/content/drive/MyDrive/stroke_segmentation_3d\")]\n",
    "        else:\n",
    "            possible_bases = [\n",
    "                Path.cwd(),\n",
    "                Path(\"/mnt/e/FINIAL PROJECT\"), \n",
    "                Path(\"/mnt/d/FINIAL PROJECT\"),\n",
    "                Path(\"/mnt/c/FINIAL PROJECT\"),\n",
    "                Path.home() / \"FINIAL PROJECT\",\n",
    "                Path.home() / \"stroke_segmentation\"\n",
    "            ]\n",
    "        \n",
    "        self.BASE_PATH = next((p for p in possible_bases if p.exists()), Path.cwd())\n",
    "        \n",
    "        # Auto-detect ISLES-2022 structure (handle nested folders)\n",
    "        self.ISLES_PATH = self._find_isles_dataset()\n",
    "        \n",
    "        self.OUTPUT_DIRS = {\n",
    "            'preprocessed_universal': self.BASE_PATH / self.folder_names['preprocessed'],\n",
    "            'aligned_multimodal': self.BASE_PATH / self.folder_names['aligned'],\n",
    "            'dl_focus_slices_2_multimodal': self.BASE_PATH / self.folder_names['slices'],\n",
    "            'dl_focus_labels_2_multimodal': self.BASE_PATH / self.folder_names['labels'], \n",
    "            'saved_models_3d': self.BASE_PATH / self.folder_names['models'],\n",
    "            'training_logs_3d': self.BASE_PATH / self.folder_names['logs'],\n",
    "            'checkpoints_3d': self.BASE_PATH / self.folder_names['checkpoints']\n",
    "        }\n",
    "        for path in self.OUTPUT_DIRS.values():\n",
    "            path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    def _find_isles_dataset(self):\n",
    "        \"\"\"Simple ISLES-2022 detection: handle double vs single folder\"\"\"\n",
    "        # Try nested first (compression issue case)\n",
    "        nested_path = self.BASE_PATH / \"ISLES-2022\" / \"ISLES-2022\"\n",
    "        if self._validate_isles_path(nested_path):\n",
    "            logger.info(f\"Found nested ISLES dataset: {nested_path}\")\n",
    "            return nested_path\n",
    "        \n",
    "        # Try single folder\n",
    "        single_path = self.BASE_PATH / \"ISLES-2022\"\n",
    "        if self._validate_isles_path(single_path):\n",
    "            logger.info(f\"Found single ISLES dataset: {single_path}\")\n",
    "            return single_path\n",
    "        \n",
    "        # Default to nested structure\n",
    "        logger.warning(f\"ISLES dataset not found, using default: {nested_path}\")\n",
    "        return nested_path\n",
    "    \n",
    "    def _validate_isles_path(self, path):\n",
    "        \"\"\"Validate ISLES-2022 dataset structure\"\"\"\n",
    "        if not path.exists():\n",
    "            return False\n",
    "        \n",
    "        # Check for patient folders directly in path with proper structure\n",
    "        patient_count = 0\n",
    "        for patient_dir in path.glob('sub-strokecase*'):\n",
    "            if patient_dir.is_dir():\n",
    "                # Check if has proper structure (ses-0001/dwi)\n",
    "                dwi_path = patient_dir / \"ses-0001\" / \"dwi\"\n",
    "                if dwi_path.exists():\n",
    "                    patient_count += 1\n",
    "        \n",
    "        # Also check if derivatives folder exists (for masks)\n",
    "        derivatives_valid = (path / 'derivatives').exists()\n",
    "        \n",
    "        return patient_count > 10 and derivatives_valid\n",
    "    \n",
    "    def _setup_training(self):\n",
    "        self.TRAINING = {\n",
    "            'EPOCHS': 100, 'BATCH_SIZE': 2, 'LEARNING_RATE': 1e-4, 'WEIGHT_DECAY': 2e-4,\n",
    "            'PATCH_SIZE': (112, 112, 80), 'PATCHES_PER_VOLUME': 4, 'ACCUMULATION_STEPS': 4,\n",
    "            'PATIENCE': 15, 'LR_PATIENCE': 10, 'USE_AMP': True, 'POSITIVE_RATIO': 0.85,\n",
    "            'TRAIN_SPLIT': 0.8, 'RANDOM_SEED': 42\n",
    "        }\n",
    "        self.MODEL = {\n",
    "            'IN_CHANNELS': 2, 'OUT_CHANNELS': 1, 'INIT_FEATURES': 64, 'USE_ATTENTION': True, \n",
    "            'DROPOUT': 0.15, 'TVERSKY_WEIGHT': 0.7, 'BOUNDARY_WEIGHT': 0.3\n",
    "        }\n",
    "        self.MIN_DATASET_SIZE = 200\n",
    "        self.SKIP_THRESHOLD = 0.62\n",
    "        \n",
    "        torch.manual_seed(42)\n",
    "        np.random.seed(42)\n",
    "        random.seed(42)\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.manual_seed_all(42)\n",
    "    \n",
    "    def _setup_preprocessing_config(self):\n",
    "        \"\"\"Setup preprocessing configuration\"\"\"\n",
    "        self.PREPROCESSING = {\n",
    "            # Advanced 2-modality configuration: DWI + ADC only\n",
    "            'MODALITY_CONFIGS': {\n",
    "                'DWI': {\n",
    "                    'patterns': ['_dwi.nii', '_DWI.nii', '_DWI_M.nii', 'DWI.nii'],\n",
    "                    'gaussian_sigma': 0.3\n",
    "                },\n",
    "                'ADC': {\n",
    "                    'patterns': ['_adc.nii', '_ADC.nii', '_ADC_M.nii', 'ADC.nii'],\n",
    "                    'gaussian_sigma': 0.3\n",
    "                }\n",
    "            },\n",
    "            \n",
    "            # Target dimensions\n",
    "            'TARGET_SHAPE': (224, 224, 144),\n",
    "            'TARGET_SPACING': (1.0, 1.0, 1.0),\n",
    "            \n",
    "        }\n",
    "\n",
    "    def get_path(self, path_key: str) -> Path:\n",
    "        return self.OUTPUT_DIRS.get(path_key, self.BASE_PATH)\n",
    "    \n",
    "    def display_paths(self):\n",
    "        \"\"\"Display detected ISLES dataset info\"\"\"\n",
    "        logger.info(\"=\" * 60)\n",
    "        logger.info(\"ISLES-2022 DATASET DETECTION\")\n",
    "        logger.info(\"=\" * 60)\n",
    "        logger.info(f\"Base Path: {self.BASE_PATH}\")\n",
    "        logger.info(f\"ISLES Path: {self.ISLES_PATH}\")\n",
    "        logger.info(f\"Valid Dataset: {self._validate_isles_path(self.ISLES_PATH)}\")\n",
    "        \n",
    "        # Count valid patients (with DWI folder structure)\n",
    "        patient_count = 0\n",
    "        if self.ISLES_PATH.exists():\n",
    "            for patient_dir in self.ISLES_PATH.glob('sub-strokecase*'):\n",
    "                if patient_dir.is_dir():\n",
    "                    dwi_path = patient_dir / \"ses-0001\" / \"dwi\"\n",
    "                    if dwi_path.exists():\n",
    "                        patient_count += 1\n",
    "        \n",
    "        # Check derivatives for masks\n",
    "        derivatives_path = self.ISLES_PATH / 'derivatives'\n",
    "        mask_count = 0\n",
    "        if derivatives_path.exists():\n",
    "            mask_count = len([p for p in derivatives_path.glob('sub-strokecase*') if p.is_dir()])\n",
    "        \n",
    "        logger.info(f\"Patients with DWI/ADC: {patient_count}\")\n",
    "        logger.info(f\"Patients with Masks: {mask_count}\")\n",
    "        logger.info(f\"Modalities: DWI + ADC (2-channel)\")\n",
    "        logger.info(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff17ba35",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "Cell 2: Configuration"
   },
   "outputs": [],
   "source": [
    "config = Config()\n",
    "\n",
    "\n",
    "def load_nifti(filepath):\n",
    "    \"\"\"Load NIfTI file safely\"\"\"\n",
    "    try:\n",
    "        img = nib.load(str(filepath))\n",
    "        return img.get_fdata().astype(np.float32), img.affine, img.header\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading {filepath}: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "def save_nifti(data, affine, header, output_path):\n",
    "    \"\"\"Save NIfTI file\"\"\"\n",
    "    try:\n",
    "        img = nib.Nifti1Image(data.astype(np.float32), affine, header)\n",
    "        nib.save(img, str(output_path))\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error saving {output_path}: {e}\")\n",
    "        return False\n",
    "\n",
    "def detect_modality(file_path):\n",
    "    \"\"\"Detect MRI modality from filename using configuration patterns\"\"\"\n",
    "    file_name = Path(file_path).name.lower()\n",
    "\n",
    "    modality_configs = config.PREPROCESSING['MODALITY_CONFIGS']\n",
    "    for modality, modality_config in modality_configs.items():\n",
    "        for pattern in modality_config['patterns']:\n",
    "            if pattern.lower() in file_name:\n",
    "                return modality\n",
    "    return None\n",
    "\n",
    "def apply_gaussian_smoothing(image, sigma=0.5):\n",
    "    \"\"\"Apply Gaussian smoothing for noise reduction\"\"\"\n",
    "    return gaussian_filter(image.astype(np.float32), sigma=sigma)\n",
    "\n",
    "def preprocess_modality_complete(image_data, modality_type):\n",
    "    \"\"\"Complete preprocessing pipeline matching merger_2_mod.py exactly\"\"\"\n",
    "    modality_config = config.PREPROCESSING['MODALITY_CONFIGS'][modality_type]\n",
    "\n",
    "    # Step 1: Clip negative values for certain modalities\n",
    "    if modality_type in ['DWI', 'ADC']:\n",
    "        image_data = np.clip(image_data, 0, None)\n",
    "\n",
    "    # Step 2: Gaussian smoothing for noise reduction\n",
    "    processed = apply_gaussian_smoothing(\n",
    "        image_data,\n",
    "        sigma=modality_config['gaussian_sigma']\n",
    "    )\n",
    "\n",
    "    # Step 3: Raw values preserved - NO normalization applied\n",
    "    # Training-time normalization handled by dataset_3d.py\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7964ff6c",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "Cell 3: Stage 1 - Preprocessing"
   },
   "outputs": [],
   "source": [
    "# Stage 1: SKIP FUNCTION - Preprocessing\n",
    "def run_stage_1_preprocessing():\n",
    "    \"\"\"Skip if preprocessed data exists\"\"\"\n",
    "    preprocessed_dir = config.get_path('preprocessed_universal')\n",
    "    # Check for new folder structure: dwi/ and adc/ subfolders\n",
    "    dwi_files = list(preprocessed_dir.glob(\"dwi/*.nii*\")) if preprocessed_dir.exists() else []\n",
    "    adc_files = list(preprocessed_dir.glob(\"adc/*.nii*\")) if preprocessed_dir.exists() else []\n",
    "    total_files = len(dwi_files) + len(adc_files)\n",
    "    \n",
    "    if total_files >= config.MIN_DATASET_SIZE:\n",
    "        logger.info(\"SKIP: Stage 1 - Preprocessed data already exists\")\n",
    "        return True\n",
    "    \n",
    "    logger.info(\"Starting Stage 1: Universal Preprocessing\")\n",
    "    isles_files = find_isles_files()\n",
    "    all_files = [f for files in isles_files.values() for f in files]\n",
    "    \n",
    "    if not all_files:\n",
    "        logger.error(\"No ISLES files found\")\n",
    "        return False\n",
    "    \n",
    "    processed = 0\n",
    "    for file_path in tqdm(all_files, desc=\"Preprocessing\"):\n",
    "        if preprocess_volume(file_path, str(preprocessed_dir)):\n",
    "            processed += 1\n",
    "    \n",
    "    logger.info(f\"Stage 1 Complete: {processed} files processed\")\n",
    "    return processed > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21859b8",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "Cell 4: Stage 2-4 (Alignment + Export)"
   },
   "outputs": [],
   "source": [
    "# Stage 2: SKIP FUNCTION - Alignment\n",
    "def process_all_patients_aligned():\n",
    "    \"\"\"Skip if aligned data exists\"\"\"\n",
    "    aligned_dir = config.get_path('aligned_multimodal')\n",
    "    if aligned_dir.exists() and len(list(aligned_dir.glob(\"**/dwi_aligned_*.nii.gz\"))) >= config.MIN_DATASET_SIZE:\n",
    "        logger.info(\"SKIP: Stage 2 - Aligned data already exists\")\n",
    "        return True\n",
    "    \n",
    "    logger.info(\"Starting Stage 2: Advanced Alignment\")\n",
    "    patient_ids = get_patient_ids()\n",
    "    \n",
    "    successful = 0\n",
    "    for patient_id in tqdm(patient_ids, desc=\"Advanced Alignment\"):\n",
    "        if process_patient_aligned(patient_id):\n",
    "            successful += 1\n",
    "    \n",
    "    logger.info(f\"Stage 2 Complete: {successful} patients processed\")\n",
    "    return successful > 0\n",
    "\n",
    "# Stage 3: SKIP FUNCTION - Export\n",
    "def run_stage_3_export():\n",
    "    \"\"\"Skip if export data exists\"\"\"\n",
    "    slices_dir = config.get_path('dl_focus_slices_2_multimodal')\n",
    "    if slices_dir.exists() and len(list(slices_dir.glob(\"*.npy\"))) >= config.MIN_DATASET_SIZE:\n",
    "        logger.info(\"SKIP: Stage 3 - Export data already exists\")\n",
    "        return True\n",
    "    \n",
    "    logger.info(\"Starting Stage 3: Training Data Export\")\n",
    "    patient_ids = get_patient_ids()\n",
    "    \n",
    "    successful = 0\n",
    "    for patient_id in tqdm(patient_ids, desc=\"Data Export\"):\n",
    "        if export_patient_data(patient_id):\n",
    "            successful += 1\n",
    "    \n",
    "    logger.info(f\"Stage 3 Complete: {successful} patients exported\")\n",
    "    return successful > 0\n",
    "\n",
    "# Stage 4: SKIP FUNCTION - Training\n",
    "def run_stage_4_training():\n",
    "    \"\"\"Skip if high-performance model exists\"\"\"\n",
    "    saved_models_dir = config.get_path('saved_models_3d')\n",
    "    if not saved_models_dir.exists():\n",
    "        return False\n",
    "    \n",
    "    model_files = list(saved_models_dir.glob(\"*_dice*.pth\"))\n",
    "    best_dice = 0.0\n",
    "    \n",
    "    for model_file in model_files:\n",
    "        try:\n",
    "            checkpoint = torch.load(model_file, map_location='cpu', weights_only=False)\n",
    "            if 'best_dice' in checkpoint:\n",
    "                dice_score = float(checkpoint['best_dice'])\n",
    "                if dice_score > best_dice:\n",
    "                    best_dice = dice_score\n",
    "                    if dice_score >= config.SKIP_THRESHOLD:\n",
    "                        logger.info(f\"SKIP: Stage 4 - High-performance model exists (Dice: {dice_score:.4f})\")\n",
    "                        return True\n",
    "        except Exception:\n",
    "            continue\n",
    "    \n",
    "    logger.info(f\"No high-performance model found (best: {best_dice:.4f}). Training required\")\n",
    "    return False\n",
    "\n",
    "def find_isles_files():\n",
    "    \"\"\"Find DWI and ADC files in ISLES dataset\"\"\"\n",
    "    found_files = {'DWI': [], 'ADC': []}\n",
    "    if not config.ISLES_PATH.exists():\n",
    "        return found_files\n",
    "    \n",
    "    # ISLES-2022 structure: DWI/ADC files are in sub-*/ses-0001/dwi/\n",
    "    for subject_dir in config.ISLES_PATH.iterdir():\n",
    "        if not subject_dir.is_dir() or not subject_dir.name.startswith('sub-strokecase'):\n",
    "            continue\n",
    "        \n",
    "        dwi_dir = subject_dir / \"ses-0001\" / \"dwi\"\n",
    "        if dwi_dir.exists():\n",
    "            for nii_file in dwi_dir.glob(\"*.nii.gz\"):\n",
    "                modality = detect_modality(str(nii_file))\n",
    "                if modality in found_files:\n",
    "                    found_files[modality].append(str(nii_file))\n",
    "    \n",
    "    return found_files\n",
    "\n",
    "def preprocess_volume(file_path, output_base_dir):\n",
    "    \"\"\"Preprocess single volume with proper folder structure\"\"\"\n",
    "    try:\n",
    "        modality = detect_modality(file_path)\n",
    "        if not modality:\n",
    "            return False\n",
    "        \n",
    "        data, affine, header = load_nifti(file_path)\n",
    "        if data is None:\n",
    "            return False\n",
    "        \n",
    "        processed_data = preprocess_modality_complete(data, modality)\n",
    "        \n",
    "        # Create separate folders for DWI and ADC\n",
    "        modality_folder = Path(output_base_dir) / modality.lower()\n",
    "        modality_folder.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        output_filename = f\"{modality.lower()}_{os.path.basename(file_path)}\"\n",
    "        output_path = modality_folder / output_filename\n",
    "        \n",
    "        return save_nifti(processed_data, affine, header, output_path)\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def get_patient_ids():\n",
    "    \"\"\"Get list of patient IDs from ISLES dataset\"\"\"\n",
    "    if not config.ISLES_PATH.exists():\n",
    "        logger.warning(f\"ISLES path does not exist: {config.ISLES_PATH}\")\n",
    "        return []\n",
    "    \n",
    "    patient_ids = []\n",
    "    \n",
    "    # ISLES-2022 structure: patient folders are directly in ISLES_PATH\n",
    "    for subject_dir in config.ISLES_PATH.iterdir():\n",
    "        if subject_dir.is_dir() and subject_dir.name.startswith('sub-strokecase'):\n",
    "            # Verify it has the expected structure (ses-0001/dwi folder)\n",
    "            dwi_path = subject_dir / \"ses-0001\" / \"dwi\"\n",
    "            if dwi_path.exists():\n",
    "                patient_ids.append(f\"{subject_dir.name}_ses-0001\")\n",
    "    \n",
    "    return sorted(patient_ids)\n",
    "\n",
    "def advanced_resample_mask_with_onehot(mask_data, scale_factors, target_shape):\n",
    "    \"\"\"Advanced mask resampling: one-hot -> linear -> argmax for better small lesion preservation\"\"\"\n",
    "    unique_labels = np.unique(mask_data).astype(int)\n",
    "    \n",
    "    if len(unique_labels) == 1:\n",
    "        resampled_data = ndimage.zoom(mask_data, scale_factors, order=0, mode='constant', cval=0)\n",
    "        if resampled_data.shape != target_shape:\n",
    "            resampled_data = pad_or_crop_to_exact_shape(resampled_data, target_shape)\n",
    "        return resampled_data\n",
    "    \n",
    "    # Step 1: Convert to one-hot encoding\n",
    "    one_hot = np.zeros((len(unique_labels),) + mask_data.shape, dtype=np.float32)\n",
    "    for i, label in enumerate(unique_labels):\n",
    "        one_hot[i] = (mask_data == label).astype(np.float32)\n",
    "    \n",
    "    # Step 2: Linear interpolation for each class\n",
    "    resampled_one_hot = np.zeros((len(unique_labels),) + target_shape, dtype=np.float32)\n",
    "    \n",
    "    for i, label in enumerate(unique_labels):\n",
    "        resampled_channel = ndimage.zoom(\n",
    "            one_hot[i], \n",
    "            scale_factors, \n",
    "            order=1,\n",
    "            mode='constant', \n",
    "            cval=0.0,\n",
    "            prefilter=False\n",
    "        )\n",
    "        \n",
    "        if resampled_channel.shape != target_shape:\n",
    "            resampled_channel = pad_or_crop_to_exact_shape(resampled_channel, target_shape)\n",
    "        \n",
    "        resampled_one_hot[i] = resampled_channel\n",
    "    \n",
    "    # Step 3: Argmax to get final segmentation\n",
    "    final_indices = np.argmax(resampled_one_hot, axis=0)\n",
    "    \n",
    "    # Convert indices back to original label values\n",
    "    resampled_mask = np.zeros(target_shape, dtype=mask_data.dtype)\n",
    "    for i, label in enumerate(unique_labels):\n",
    "        resampled_mask[final_indices == i] = label\n",
    "    \n",
    "    return resampled_mask\n",
    "\n",
    "def align_simple(source_img, target_spacing, target_shape, is_mask=False):\n",
    "    \"\"\"Advanced Simple Alignment: Direct resampling to 1x1x1mm³ with 3rd order spline\"\"\"\n",
    "    source_data = source_img.get_fdata()\n",
    "    source_shape = source_data.shape\n",
    "    source_spacing = source_img.header.get_zooms()[:3]\n",
    "    \n",
    "    # Skip resampling if already correct\n",
    "    if source_shape == target_shape and np.allclose(source_spacing, target_spacing, rtol=1e-3):\n",
    "        return source_data, source_img.affine, source_spacing\n",
    "    \n",
    "    # Calculate scaling factors\n",
    "    scale_factors = np.array(source_spacing) / np.array(target_spacing)\n",
    "    \n",
    "    # Create clean diagonal affine matrix\n",
    "    new_affine = np.eye(4)\n",
    "    new_affine[0, 0] = target_spacing[0]\n",
    "    new_affine[1, 1] = target_spacing[1] \n",
    "    new_affine[2, 2] = target_spacing[2]\n",
    "    new_affine[:3, 3] = source_img.affine[:3, 3]\n",
    "    \n",
    "    if is_mask:\n",
    "        # Use advanced mask resampling for ground truth\n",
    "        resampled_data = advanced_resample_mask_with_onehot(source_data, scale_factors, target_shape)\n",
    "    else:\n",
    "        # 3rd order spline for image modalities (DWI, ADC)\n",
    "        resampled_data = ndimage.zoom(\n",
    "            source_data, \n",
    "            scale_factors, \n",
    "            order=3,\n",
    "            mode='constant', \n",
    "            cval=0.0,\n",
    "            prefilter=True\n",
    "        )\n",
    "        \n",
    "        # Ensure exact target shape\n",
    "        if resampled_data.shape != target_shape:\n",
    "            resampled_data = pad_or_crop_to_exact_shape(resampled_data, target_shape)\n",
    "    \n",
    "    return resampled_data, new_affine, target_spacing\n",
    "\n",
    "\n",
    "def pad_or_crop_to_exact_shape(data, target_shape):\n",
    "    \"\"\"Pad or crop data to exact target shape (Advanced methodology).\"\"\"\n",
    "    current_shape = data.shape\n",
    "    \n",
    "    # First crop if any dimension is larger\n",
    "    slices = []\n",
    "    for current, target in zip(current_shape, target_shape):\n",
    "        if current > target:\n",
    "            # Crop: take center portion\n",
    "            start = (current - target) // 2\n",
    "            slices.append(slice(start, start + target))\n",
    "        else:\n",
    "            slices.append(slice(None))\n",
    "    \n",
    "    # Crop the array\n",
    "    if any(s != slice(None) for s in slices):\n",
    "        data = data[tuple(slices)]\n",
    "    \n",
    "    # Now pad if any dimension is smaller\n",
    "    current_shape = data.shape\n",
    "    padding = []\n",
    "    for current, target in zip(current_shape, target_shape):\n",
    "        if current < target:\n",
    "            diff = target - current\n",
    "            pad_before = diff // 2\n",
    "            pad_after = diff - pad_before\n",
    "            padding.append((pad_before, pad_after))\n",
    "        else:\n",
    "            padding.append((0, 0))\n",
    "    \n",
    "    if any(p != (0, 0) for p in padding):\n",
    "        data = np.pad(data, padding, mode='constant', constant_values=0)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def process_patient_aligned(patient_id):\n",
    "    \"\"\"Process single patient with Advanced alignment using align_simple (DWI + ADC + MASKS)\"\"\"\n",
    "    try:\n",
    "        # Find patient files (DWI + ADC + MASK)\n",
    "        dwi_file = find_patient_file(patient_id, 'DWI')\n",
    "        adc_file = find_patient_file(patient_id, 'ADC')\n",
    "        mask_file = find_patient_file(patient_id, 'MASK')\n",
    "        \n",
    "        if not dwi_file or not adc_file:\n",
    "            return False\n",
    "            \n",
    "        target_spacing = (1.0, 1.0, 1.0)\n",
    "        target_shape = (224, 224, 144)\n",
    "        \n",
    "        output_path = config.get_path('aligned_multimodal')\n",
    "        \n",
    "        # Create output directories\n",
    "        for subdir in ['dwi', 'adc', 'masks']:\n",
    "            (output_path / subdir).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # STEP 1: Process DWI with 3rd order spline\n",
    "        dwi_img = nib.load(dwi_file)\n",
    "        dwi_aligned_data, dwi_new_affine, dwi_final_spacing = align_simple(\n",
    "            dwi_img, target_spacing, target_shape, is_mask=False\n",
    "        )\n",
    "        \n",
    "        # Save aligned DWI\n",
    "        dwi_output_file = output_path / \"dwi\" / f\"dwi_aligned_{patient_id}_DWI.nii.gz\"\n",
    "        dwi_aligned_img = nib.Nifti1Image(dwi_aligned_data, dwi_new_affine)\n",
    "        nib.save(dwi_aligned_img, dwi_output_file)\n",
    "        \n",
    "        # STEP 2: Process ADC with 3rd order spline\n",
    "        adc_img = nib.load(adc_file)\n",
    "        adc_aligned_data, adc_new_affine, adc_final_spacing = align_simple(\n",
    "            adc_img, target_spacing, target_shape, is_mask=False\n",
    "        )\n",
    "        \n",
    "        # Save aligned ADC\n",
    "        adc_output_file = output_path / \"adc\" / f\"adc_aligned_{patient_id}_ADC.nii.gz\"\n",
    "        adc_aligned_img = nib.Nifti1Image(adc_aligned_data, adc_new_affine)\n",
    "        nib.save(adc_aligned_img, adc_output_file)\n",
    "        \n",
    "        # Process ground truth mask (using resample_image for masks)\n",
    "        if mask_file:\n",
    "            gt_img = nib.load(mask_file)\n",
    "            aligned_mask, new_affine, final_spacing = align_simple(\n",
    "                gt_img, target_spacing, target_shape, is_mask=True\n",
    "            )\n",
    "            \n",
    "            # Save aligned mask\n",
    "            mask_filename = f\"mask_aligned_{patient_id}_msk.nii.gz\"\n",
    "            mask_output_file = output_path / \"masks\" / mask_filename\n",
    "            \n",
    "            mask_img = nib.Nifti1Image(aligned_mask, new_affine)\n",
    "            nib.save(mask_img, mask_output_file)\n",
    "        \n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def find_patient_file(patient_id, modality):\n",
    "    \"\"\"Find patient file by modality in ISLES dataset\"\"\"\n",
    "    base_patient = patient_id.split('_ses-')[0]\n",
    "    \n",
    "    # ISLES-2022 structure: DWI/ADC files are in sub-*/ses-0001/dwi/\n",
    "    if modality in ['DWI', 'ADC']:\n",
    "        dwi_dir = config.ISLES_PATH / base_patient / \"ses-0001\" / \"dwi\"\n",
    "        if dwi_dir.exists():\n",
    "            for nii_file in dwi_dir.glob(\"*.nii.gz\"):\n",
    "                if detect_modality(str(nii_file)) == modality:\n",
    "                    return str(nii_file)\n",
    "    \n",
    "    # Mask files are in derivatives/sub-*/ses-0001/\n",
    "    elif modality == 'MASK':\n",
    "        mask_dir = config.ISLES_PATH / \"derivatives\" / base_patient / \"ses-0001\"\n",
    "        if mask_dir.exists():\n",
    "            for mask_file in mask_dir.glob(\"*_msk.nii.gz\"):\n",
    "                return str(mask_file)\n",
    "    \n",
    "    return None\n",
    "\n",
    "def export_patient_data(patient_id):\n",
    "    \"\"\"Export patient data for training\"\"\"\n",
    "    try:\n",
    "        aligned_dir = config.get_path('aligned_multimodal')\n",
    "        dwi_path = aligned_dir / 'dwi' / f\"dwi_aligned_{patient_id}_DWI.nii.gz\"\n",
    "        adc_path = aligned_dir / 'adc' / f\"adc_aligned_{patient_id}_ADC.nii.gz\"\n",
    "        \n",
    "        if not dwi_path.exists() or not adc_path.exists():\n",
    "            return False\n",
    "        \n",
    "        dwi_data, _, _ = load_nifti(dwi_path)\n",
    "        adc_data, _, _ = load_nifti(adc_path)\n",
    "        \n",
    "        if dwi_data is None or adc_data is None:\n",
    "            return False\n",
    "        \n",
    "        # Stack modalities (2-modality: DWI + ADC)\n",
    "        multimodal = np.stack([dwi_data, adc_data], axis=0)\n",
    "        \n",
    "        # Load aligned ground truth masks for training consistency\n",
    "        aligned_dir = config.get_path('aligned_multimodal')\n",
    "        mask_path = aligned_dir / 'masks' / f\"mask_aligned_{patient_id}_msk.nii.gz\"\n",
    "        \n",
    "        if mask_path.exists():\n",
    "            mask_data, _, _ = load_nifti(mask_path)\n",
    "            if mask_data is not None:\n",
    "                labels = (mask_data > 0.5).astype(np.uint8)\n",
    "            else:\n",
    "                labels = np.zeros_like(dwi_data, dtype=np.uint8)\n",
    "        else:\n",
    "            # Fallback: if no aligned mask, create zeros (for patients without lesions)\n",
    "            labels = np.zeros_like(dwi_data, dtype=np.uint8)\n",
    "        \n",
    "        # Save training data\n",
    "        slices_dir = config.get_path('dl_focus_slices_2_multimodal')\n",
    "        labels_dir = config.get_path('dl_focus_labels_2_multimodal')\n",
    "        \n",
    "        slice_file = slices_dir / f\"{patient_id}_focus_slices_2_multimodal.npy\"\n",
    "        label_file = labels_dir / f\"{patient_id}_focus_labels_2_multimodal.npy\"\n",
    "        \n",
    "        np.save(slice_file, multimodal.astype(np.float32))\n",
    "        np.save(label_file, labels)\n",
    "        \n",
    "        return True\n",
    "    except Exception:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3931c220",
   "metadata": {
    "title": "Cell 5: Dataset Loader"
   },
   "outputs": [],
   "source": [
    "class MemoryEfficientConvBlock(nn.Module):\n",
    "    \"\"\"Memory-efficient 3D convolution block\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn1 = nn.InstanceNorm3d(out_channels, affine=True)\n",
    "        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.InstanceNorm3d(out_channels, affine=True)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dropout = nn.Dropout3d(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class AttentionGate3D(nn.Module):\n",
    "    \"\"\"3D Attention gate for focusing on small lesions\"\"\"\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super().__init__()\n",
    "        self.W_g = nn.Sequential(\n",
    "            nn.Conv3d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.InstanceNorm3d(F_int, affine=True)\n",
    "        )\n",
    "        \n",
    "        self.W_x = nn.Sequential(\n",
    "            nn.Conv3d(F_l, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.InstanceNorm3d(F_int, affine=True)\n",
    "        )\n",
    "        \n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv3d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.InstanceNorm3d(1, affine=True),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, g, x):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.relu(g1 + x1)\n",
    "        psi = self.psi(psi)\n",
    "        return x * psi\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    \"\"\"Encoder block with gradient checkpointing\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, use_checkpoint=True, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.use_checkpoint = use_checkpoint\n",
    "        self.conv_block = MemoryEfficientConvBlock(in_channels, out_channels, dropout)\n",
    "        self.pool = nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.use_checkpoint and self.training:\n",
    "            try:\n",
    "                x_conv = checkpoint(self.conv_block, x, use_reentrant=False)\n",
    "            except TypeError:\n",
    "                x_conv = checkpoint(self.conv_block, x)\n",
    "        else:\n",
    "            x_conv = self.conv_block(x)\n",
    "        x_pooled = self.pool(x_conv)\n",
    "        return x_pooled, x_conv\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    \"\"\"Decoder block with attention\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, use_checkpoint=True, use_attention=True, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.use_checkpoint = use_checkpoint\n",
    "        self.use_attention = use_attention\n",
    "        \n",
    "        self.upconv = nn.ConvTranspose3d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "        self.conv_block = MemoryEfficientConvBlock(in_channels, out_channels, dropout)\n",
    "        \n",
    "        if use_attention:\n",
    "            self.attention = AttentionGate3D(F_g=in_channels//2, F_l=in_channels//2, F_int=max(1, out_channels//2))\n",
    "    \n",
    "    def _pad_to_match(self, x_decoder, x_skip):\n",
    "        diffZ = x_skip.size()[2] - x_decoder.size()[2]\n",
    "        diffY = x_skip.size()[3] - x_decoder.size()[3]\n",
    "        diffX = x_skip.size()[4] - x_decoder.size()[4]\n",
    "        \n",
    "        x_decoder = F.pad(x_decoder, [diffX // 2, diffX - diffX // 2,\n",
    "                                     diffY // 2, diffY - diffY // 2,\n",
    "                                     diffZ // 2, diffZ - diffZ // 2])\n",
    "        return x_decoder\n",
    "    \n",
    "    def forward(self, x_decoder, x_skip):\n",
    "        x_decoder = self.upconv(x_decoder)\n",
    "        x_decoder = self._pad_to_match(x_decoder, x_skip)\n",
    "        \n",
    "        if self.use_attention:\n",
    "            x_skip = self.attention(g=x_decoder, x=x_skip)\n",
    "        \n",
    "        x = torch.cat([x_decoder, x_skip], dim=1)\n",
    "        \n",
    "        if self.use_checkpoint and self.training:\n",
    "            try:\n",
    "                x = checkpoint(self.conv_block, x, use_reentrant=False)\n",
    "            except TypeError:\n",
    "                x = checkpoint(self.conv_block, x)\n",
    "        else:\n",
    "            x = self.conv_block(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class UNet3D_Refactored(nn.Module):\n",
    "    \"\"\"3D U-Net for stroke lesion segmentation\"\"\"\n",
    "    def __init__(self, in_channels=2, out_channels=1, init_features=48, \n",
    "                 use_checkpoint=True, use_attention=True, dropout=0.15, deep_supervision=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.use_checkpoint = use_checkpoint\n",
    "        self.deep_supervision = deep_supervision\n",
    "        features = init_features\n",
    "        \n",
    "        # Encoder path\n",
    "        self.encoder1 = EncoderBlock(in_channels, features, use_checkpoint, dropout)\n",
    "        self.encoder2 = EncoderBlock(features, features * 2, use_checkpoint, dropout)\n",
    "        self.encoder3 = EncoderBlock(features * 2, features * 4, use_checkpoint, dropout)\n",
    "        self.encoder4 = EncoderBlock(features * 4, features * 8, use_checkpoint, dropout)\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.bottleneck = MemoryEfficientConvBlock(features * 8, features * 16, dropout)\n",
    "        \n",
    "        # Decoder path\n",
    "        self.decoder4 = DecoderBlock(features * 16, features * 8, use_checkpoint, use_attention, dropout)\n",
    "        self.decoder3 = DecoderBlock(features * 8, features * 4, use_checkpoint, use_attention, dropout)\n",
    "        self.decoder2 = DecoderBlock(features * 4, features * 2, use_checkpoint, use_attention, dropout)\n",
    "        self.decoder1 = DecoderBlock(features * 2, features, use_checkpoint, use_attention, dropout)\n",
    "        \n",
    "        # Final classification layer\n",
    "        self.final_conv = nn.Conv3d(features, out_channels, kernel_size=1)\n",
    "        \n",
    "        # Deep supervision outputs\n",
    "        if self.deep_supervision:\n",
    "            self.deep_conv4 = nn.Conv3d(features * 8, out_channels, kernel_size=1)\n",
    "            self.deep_conv3 = nn.Conv3d(features * 4, out_channels, kernel_size=1)\n",
    "            self.deep_conv2 = nn.Conv3d(features * 2, out_channels, kernel_size=1)\n",
    "            \n",
    "            self.deep_upsample4 = nn.Upsample(scale_factor=8, mode='trilinear', align_corners=False)\n",
    "            self.deep_upsample3 = nn.Upsample(scale_factor=4, mode='trilinear', align_corners=False)\n",
    "            self.deep_upsample2 = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=False)\n",
    "        \n",
    "        self._initialize_weights()\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv3d):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, (nn.BatchNorm3d, nn.InstanceNorm3d)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encoder path\n",
    "        enc1_pool, enc1_conv = self.encoder1(x)\n",
    "        enc2_pool, enc2_conv = self.encoder2(enc1_pool)\n",
    "        enc3_pool, enc3_conv = self.encoder3(enc2_pool)\n",
    "        enc4_pool, enc4_conv = self.encoder4(enc3_pool)\n",
    "        \n",
    "        # Bottleneck\n",
    "        if self.use_checkpoint and self.training:\n",
    "            try:\n",
    "                bottleneck = checkpoint(self.bottleneck, enc4_pool, use_reentrant=False)\n",
    "            except TypeError:\n",
    "                bottleneck = checkpoint(self.bottleneck, enc4_pool)\n",
    "        else:\n",
    "            bottleneck = self.bottleneck(enc4_pool)\n",
    "        \n",
    "        # Decoder path\n",
    "        dec4 = self.decoder4(bottleneck, enc4_conv)\n",
    "        dec3 = self.decoder3(dec4, enc3_conv)\n",
    "        dec2 = self.decoder2(dec3, enc2_conv)\n",
    "        dec1 = self.decoder1(dec2, enc1_conv)\n",
    "        \n",
    "        # Final output\n",
    "        main_output = self.final_conv(dec1)\n",
    "        \n",
    "        # Deep supervision outputs\n",
    "        if self.deep_supervision and self.training:\n",
    "            deep_output4 = self.deep_upsample4(self.deep_conv4(dec4))\n",
    "            deep_output3 = self.deep_upsample3(self.deep_conv3(dec3))\n",
    "            deep_output2 = self.deep_upsample2(self.deep_conv2(dec2))\n",
    "            \n",
    "            target_size = main_output.shape[2:]\n",
    "            if deep_output4.shape[2:] != target_size:\n",
    "                deep_output4 = F.interpolate(deep_output4, size=target_size, mode='trilinear', align_corners=False)\n",
    "            if deep_output3.shape[2:] != target_size:\n",
    "                deep_output3 = F.interpolate(deep_output3, size=target_size, mode='trilinear', align_corners=False)\n",
    "            if deep_output2.shape[2:] != target_size:\n",
    "                deep_output2 = F.interpolate(deep_output2, size=target_size, mode='trilinear', align_corners=False)\n",
    "            \n",
    "            return {\n",
    "                'main': main_output,\n",
    "                'aux4': deep_output4,\n",
    "                'aux3': deep_output3,\n",
    "                'aux2': deep_output2\n",
    "            }\n",
    "        else:\n",
    "            return {'main': main_output}\n",
    "\n",
    "class FocalTverskyLoss3D(nn.Module):\n",
    "    \"\"\"Focal Tversky Loss for small lesion segmentation\"\"\"\n",
    "    def __init__(self, alpha=0.25, beta=0.85, gamma=2.0, smooth=1e-6):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "        self.smooth = smooth\n",
    "    \n",
    "    def forward(self, predictions, targets):\n",
    "        preds = torch.sigmoid(predictions)\n",
    "        preds_flat = preds.view(preds.size(0), -1)\n",
    "        targets_flat = targets.view(targets.size(0), -1)\n",
    "\n",
    "        true_pos = (preds_flat * targets_flat).sum(dim=1)\n",
    "        false_pos = (preds_flat * (1 - targets_flat)).sum(dim=1)\n",
    "        false_neg = ((1 - preds_flat) * targets_flat).sum(dim=1)\n",
    "\n",
    "        tversky = (true_pos + self.smooth) / (true_pos + self.alpha * false_pos + self.beta * false_neg + self.smooth)\n",
    "        loss = torch.pow((1 - tversky), self.gamma).mean()\n",
    "        return loss\n",
    "\n",
    "class BoundaryLoss3D(nn.Module):\n",
    "    \"\"\"3D Boundary Loss for lesion edge refinement\"\"\"\n",
    "    def __init__(self, smooth=1e-6):\n",
    "        super().__init__()\n",
    "        self.smooth = smooth\n",
    "    \n",
    "    def forward(self, predictions, targets):\n",
    "        if predictions.min() < 0 or predictions.max() > 1:\n",
    "            predictions = torch.sigmoid(predictions)\n",
    "        \n",
    "        pred_grad_x = torch.abs(predictions[:, :, 1:, :, :] - predictions[:, :, :-1, :, :])\n",
    "        pred_grad_y = torch.abs(predictions[:, :, :, 1:, :] - predictions[:, :, :, :-1, :])\n",
    "        pred_grad_z = torch.abs(predictions[:, :, :, :, 1:] - predictions[:, :, :, :, :-1])\n",
    "        \n",
    "        target_grad_x = torch.abs(targets[:, :, 1:, :, :] - targets[:, :, :-1, :, :])\n",
    "        target_grad_y = torch.abs(targets[:, :, :, 1:, :] - targets[:, :, :, :-1, :])\n",
    "        target_grad_z = torch.abs(targets[:, :, :, :, 1:] - targets[:, :, :, :, :-1])\n",
    "        \n",
    "        boundary_loss = (\n",
    "            F.smooth_l1_loss(pred_grad_x, target_grad_x) +\n",
    "            F.smooth_l1_loss(pred_grad_y, target_grad_y) +\n",
    "            F.smooth_l1_loss(pred_grad_z, target_grad_z)\n",
    "        ) / 3.0\n",
    "        \n",
    "        return boundary_loss\n",
    "\n",
    "class OptimizedStrokeLoss3D(nn.Module):\n",
    "    \"\"\"Optimized dual-loss function\"\"\"\n",
    "    def __init__(self, tversky_weight=0.7, boundary_weight=0.3, enable_deep_supervision=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.tversky_weight = tversky_weight\n",
    "        self.boundary_weight = boundary_weight\n",
    "        self.enable_deep_supervision = enable_deep_supervision\n",
    "        \n",
    "        total_weight = tversky_weight + boundary_weight\n",
    "        if abs(total_weight - 1.0) > 1e-6:\n",
    "            self.tversky_weight = tversky_weight / total_weight\n",
    "            self.boundary_weight = boundary_weight / total_weight\n",
    "        \n",
    "        self.focal_tversky = FocalTverskyLoss3D(\n",
    "            alpha=Constants.TVERSKY_ALPHA, beta=Constants.TVERSKY_BETA, \n",
    "            gamma=Constants.TVERSKY_GAMMA, smooth=1e-6\n",
    "        )\n",
    "        self.boundary_loss = BoundaryLoss3D(smooth=1e-6)\n",
    "    \n",
    "    def forward(self, predictions, targets):\n",
    "        if isinstance(predictions, dict):\n",
    "            main_pred = predictions['main']\n",
    "            \n",
    "            tversky_main = self.focal_tversky(main_pred, targets)\n",
    "            boundary_main = self.boundary_loss(main_pred, targets)\n",
    "            main_loss = self.tversky_weight * tversky_main + self.boundary_weight * boundary_main\n",
    "            \n",
    "            if self.enable_deep_supervision and self.training:\n",
    "                aux_loss = 0.0\n",
    "                aux_weights = [0.6, 0.4, 0.3]\n",
    "                \n",
    "                for i, aux_key in enumerate(['aux4', 'aux3', 'aux2']):\n",
    "                    if aux_key in predictions:\n",
    "                        aux_pred = predictions[aux_key]\n",
    "                        tversky_aux = self.focal_tversky(aux_pred, targets)\n",
    "                        boundary_aux = self.boundary_loss(aux_pred, targets)\n",
    "                        aux_loss += aux_weights[i] * (self.tversky_weight * tversky_aux + self.boundary_weight * boundary_aux)\n",
    "                \n",
    "                total_loss = main_loss + aux_loss\n",
    "            else:\n",
    "                total_loss = main_loss\n",
    "                \n",
    "            return {\n",
    "                'total_loss': total_loss,\n",
    "                'tversky_loss': tversky_main,\n",
    "                'boundary_loss': boundary_main\n",
    "            }\n",
    "        else:\n",
    "            tversky_loss = self.focal_tversky(predictions, targets)\n",
    "            boundary_loss = self.boundary_loss(predictions, targets)\n",
    "            total_loss = self.tversky_weight * tversky_loss + self.boundary_weight * boundary_loss\n",
    "            \n",
    "            return {\n",
    "                'total_loss': total_loss,\n",
    "                'tversky_loss': tversky_loss,\n",
    "                'boundary_loss': boundary_loss\n",
    "            }\n",
    "\n",
    "def create_loss_function():\n",
    "    \"\"\"Create the optimized dual-loss function\"\"\"\n",
    "    return OptimizedStrokeLoss3D(\n",
    "        tversky_weight=config.MODEL['TVERSKY_WEIGHT'],\n",
    "        boundary_weight=config.MODEL['BOUNDARY_WEIGHT'],\n",
    "        enable_deep_supervision=True\n",
    "    )\n",
    "\n",
    "class StrokeLesion3DDataset(Dataset):\n",
    "    \"\"\"2-modality Dataset for stroke lesion segmentation\"\"\"\n",
    "    \n",
    "    def __init__(self, slices_dir: str, labels_dir: str, positive_ratio: float = 0.7,\n",
    "                 mode: str = 'train', use_augmentation: bool = True, patches_per_volume: int = 8,\n",
    "                 silent: bool = False):\n",
    "        \n",
    "        self.slices_dir = Path(slices_dir)\n",
    "        self.labels_dir = Path(labels_dir)\n",
    "        self.patch_size = config.TRAINING['PATCH_SIZE']\n",
    "        self.patches_per_volume = patches_per_volume\n",
    "        self.positive_ratio = positive_ratio\n",
    "        self.mode = mode\n",
    "        self.use_augmentation = use_augmentation and (mode == 'train')\n",
    "        self.silent = silent\n",
    "        \n",
    "        # Set random seed\n",
    "        random.seed(config.TRAINING['RANDOM_SEED'])\n",
    "        np.random.seed(config.TRAINING['RANDOM_SEED'])\n",
    "        \n",
    "        self.valid_cases = self._find_valid_cases()\n",
    "        \n",
    "        if mode == 'inference':\n",
    "            self.dataset_size = len(self.valid_cases)\n",
    "        else:\n",
    "            self.dataset_size = len(self.valid_cases) * self.patches_per_volume\n",
    "        \n",
    "        # SILENT MODE: Only log during initial discovery, not during training setup\n",
    "        if not self.silent:\n",
    "            logger.info(f\"Dataset size: {self.dataset_size} {'volumes' if mode == 'inference' else 'patches'}\")\n",
    "    \n",
    "    def _find_valid_cases(self) -> List[Tuple[Path, Path]]:\n",
    "        \"\"\"Find valid file pairs with fast/full mode based on usage\"\"\"\n",
    "        valid_cases = []\n",
    "        slice_files = list(self.slices_dir.glob(\"*_focus_slices_2_multimodal.npy\"))\n",
    "        \n",
    "        for slice_file in slice_files:\n",
    "            patient_id = slice_file.name.replace(\"_focus_slices_2_multimodal.npy\", \"\")\n",
    "            label_file = self.labels_dir / f\"{patient_id}_focus_labels_2_multimodal.npy\"\n",
    "            \n",
    "            if self.mode in ['train', 'val']:\n",
    "                # Fast mode for training - minimal checks\n",
    "                if label_file.exists():\n",
    "                    valid_cases.append((slice_file, label_file))\n",
    "            else:\n",
    "                # Full validation for inference\n",
    "                if label_file.exists() and slice_file.stat().st_size > 1000 and label_file.stat().st_size > 1000:\n",
    "                    valid_cases.append((slice_file, label_file))\n",
    "                \n",
    "        return sorted(valid_cases)\n",
    "    \n",
    "    \n",
    "    def _get_random_patch_center(self, volume_shape):\n",
    "        \"\"\"Get random center coordinates for patch extraction\"\"\"\n",
    "        h, w, d = volume_shape\n",
    "        ph, pw, pd = self.patch_size\n",
    "        \n",
    "        center_h = random.randint(ph//2, max(ph//2, h - ph//2 - 1))\n",
    "        center_w = random.randint(pw//2, max(pw//2, w - pw//2 - 1))\n",
    "        center_d = random.randint(pd//2, max(pd//2, d - pd//2 - 1))\n",
    "        \n",
    "        return (center_h, center_w, center_d)\n",
    "    \n",
    "    def _get_positive_patch_center(self, label_volume):\n",
    "        \"\"\"Get center coordinates for a lesion-containing patch\"\"\"\n",
    "        lesion_coords = np.argwhere(label_volume > 0.5)\n",
    "        if len(lesion_coords) > 0:\n",
    "            coord_idx = random.randint(0, len(lesion_coords) - 1)\n",
    "            return tuple(lesion_coords[coord_idx])\n",
    "        return None\n",
    "    \n",
    "    def _extract_patch(self, volume, center, patch_size):\n",
    "        \"\"\"Extract patch from volume around center coordinates\"\"\"\n",
    "        is_multichannel = (len(volume.shape) == 4)\n",
    "        if is_multichannel:\n",
    "            _, h, w, d = volume.shape\n",
    "        else:\n",
    "            h, w, d = volume.shape\n",
    "        ph, pw, pd = patch_size\n",
    "\n",
    "        start_h = max(0, min(center[0] - ph//2, h - ph))\n",
    "        start_w = max(0, min(center[1] - pw//2, w - pw))\n",
    "        start_d = max(0, min(center[2] - pd//2, d - pd))\n",
    "\n",
    "        end_h = start_h + ph\n",
    "        end_w = start_w + pw\n",
    "        end_d = start_d + pd\n",
    "\n",
    "        if is_multichannel:\n",
    "            patch = volume[:, start_h:end_h, start_w:end_w, start_d:end_d]\n",
    "            pad_h = ph - patch.shape[1]\n",
    "            pad_w = pw - patch.shape[2]\n",
    "            pad_d = pd - patch.shape[3]\n",
    "            if pad_h > 0 or pad_w > 0 or pad_d > 0:\n",
    "                pad_width = ((0, 0), (pad_h//2, pad_h-pad_h//2), (pad_w//2, pad_w-pad_w//2), (pad_d//2, pad_d-pad_d//2))\n",
    "                patch = np.pad(patch, pad_width, mode='constant', constant_values=0)\n",
    "        else:\n",
    "            patch = volume[start_h:end_h, start_w:end_w, start_d:end_d]\n",
    "            pad_h = ph - patch.shape[0]\n",
    "            pad_w = pw - patch.shape[1]\n",
    "            pad_d = pd - patch.shape[2]\n",
    "            if pad_h > 0 or pad_w > 0 or pad_d > 0:\n",
    "                pad_width = ((pad_h//2, pad_h-pad_h//2), (pad_w//2, pad_w-pad_w//2), (pad_d//2, pad_d-pad_d//2))\n",
    "                patch = np.pad(patch, pad_width, mode='constant', constant_values=0)\n",
    "\n",
    "        return patch\n",
    "    \n",
    "    def _apply_augmentations(self, slice_patch, label_patch):\n",
    "        \"\"\"Apply data augmentations\"\"\"\n",
    "        if not self.use_augmentation:\n",
    "            return slice_patch, label_patch\n",
    "        \n",
    "        if random.random() < 0.5:\n",
    "            slice_patch = np.flip(slice_patch, axis=1)\n",
    "            label_patch = np.flip(label_patch, axis=0)\n",
    "        \n",
    "        if random.random() < 0.5:\n",
    "            slice_patch = np.flip(slice_patch, axis=2)\n",
    "            label_patch = np.flip(label_patch, axis=1)\n",
    "        \n",
    "        if random.random() < 0.3:\n",
    "            for channel in range(slice_patch.shape[0]):\n",
    "                scale = random.uniform(0.9, 1.1)\n",
    "                slice_patch[channel] *= scale\n",
    "        \n",
    "        if random.random() < 0.25:\n",
    "            sigma = random.uniform(0.3, 0.7)\n",
    "            for channel in range(slice_patch.shape[0]):\n",
    "                slice_patch[channel] = gaussian_filter(slice_patch[channel], sigma)\n",
    "        \n",
    "        if random.random() < 0.3:\n",
    "            noise = np.random.normal(0, 0.02, slice_patch.shape)\n",
    "            slice_patch = slice_patch + noise\n",
    "        \n",
    "        return slice_patch, label_patch\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return self.dataset_size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Get item from dataset\"\"\"\n",
    "        \n",
    "        if self.mode == 'inference':\n",
    "            # FIXED: Prevent index out of range\n",
    "            if len(self.valid_cases) == 0:\n",
    "                raise IndexError(\"Validation set is empty!\")\n",
    "            \n",
    "            idx = idx % len(self.valid_cases)\n",
    "            slice_file, label_file = self.valid_cases[idx]\n",
    "            \n",
    "            slices = np.load(slice_file).astype(np.float32)\n",
    "            labels = np.load(label_file)\n",
    "            if labels.dtype == np.uint8:\n",
    "                labels = labels.astype(np.float32)\n",
    "            \n",
    "            slices = apply_zscore_normalization(slices)\n",
    "            \n",
    "            slice_tensor = torch.from_numpy(slices.astype(np.float32)).float()\n",
    "            label_tensor = torch.from_numpy(labels.astype(np.float32)).float().unsqueeze(0)\n",
    "            \n",
    "            return slice_tensor, label_tensor\n",
    "        \n",
    "        else:\n",
    "            # Return patch for training/validation\n",
    "            volume_idx = idx // self.patches_per_volume\n",
    "            \n",
    "            # FIXED: Prevent index out of range\n",
    "            if len(self.valid_cases) == 0:\n",
    "                raise IndexError(\"Validation set is empty!\")\n",
    "            \n",
    "            volume_idx = volume_idx % len(self.valid_cases)\n",
    "            slice_file, label_file = self.valid_cases[volume_idx]\n",
    "            \n",
    "            slices = np.load(slice_file).astype(np.float32)\n",
    "            labels = np.load(label_file)\n",
    "            if labels.dtype == np.uint8:\n",
    "                labels = labels.astype(np.float32)\n",
    "            \n",
    "            slices = apply_zscore_normalization(slices)\n",
    "            volume_shape = slices.shape[1:]\n",
    "            \n",
    "            # Choose patch center based on positive sampling\n",
    "            has_lesions = np.any(labels > 0.5)\n",
    "            \n",
    "            if has_lesions and random.random() < self.positive_ratio:\n",
    "                center = self._get_positive_patch_center(labels)\n",
    "                if center is None:\n",
    "                    center = self._get_random_patch_center(volume_shape)\n",
    "            else:\n",
    "                center = self._get_random_patch_center(volume_shape)\n",
    "            \n",
    "            # Extract patches\n",
    "            slice_patch = self._extract_patch(slices, center, self.patch_size)\n",
    "            label_patch = self._extract_patch(labels, center, self.patch_size)\n",
    "            \n",
    "            # Apply augmentations\n",
    "            slice_patch, label_patch = self._apply_augmentations(slice_patch, label_patch)\n",
    "            \n",
    "            # Convert to tensors\n",
    "            slice_tensor = torch.from_numpy(slice_patch.copy().astype(np.float32)).float()\n",
    "            label_tensor = torch.from_numpy(label_patch.copy().astype(np.float32)).float().unsqueeze(0)\n",
    "            \n",
    "            return slice_tensor, label_tensor\n",
    "\n",
    "def create_3d_dataloaders_optimized(slices_dir: str, labels_dir: str, all_cases: List, \n",
    "                                    train_indices: List[int], val_indices: List[int], \n",
    "                                    batch_size: int = 2) -> Tuple[DataLoader, DataLoader]:\n",
    "    \"\"\"Create train and validation dataloaders - OPTIMIZED (no repeated dataset creation)\"\"\"\n",
    "    \n",
    "    num_workers = 0 if COLAB_ENV else 2\n",
    "    \n",
    "    # Filter cases by indices (reuse existing all_cases)\n",
    "    train_cases = [all_cases[i] for i in train_indices if i < len(all_cases)]\n",
    "    val_cases = [all_cases[i] for i in val_indices if i < len(all_cases)]\n",
    "    \n",
    "    if len(train_cases) < 2:\n",
    "        raise ValueError(f\"Need ≥2 patients for training, got {len(train_cases)} train cases\")\n",
    "    if len(val_cases) < 1:\n",
    "        raise ValueError(f\"Need ≥1 patient for validation, got {len(val_cases)} val cases\")\n",
    "    \n",
    "    # Create datasets WITH SILENT MODE (no logging during creation)\n",
    "    train_dataset = StrokeLesion3DDataset(\n",
    "        slices_dir=slices_dir, labels_dir=labels_dir, mode='train', \n",
    "        use_augmentation=True, patches_per_volume=config.TRAINING['PATCHES_PER_VOLUME'],\n",
    "        silent=True  # Silent mode during training setup\n",
    "    )\n",
    "    \n",
    "    val_dataset = StrokeLesion3DDataset(\n",
    "        slices_dir=slices_dir, labels_dir=labels_dir, mode='val', \n",
    "        use_augmentation=False, patches_per_volume=config.TRAINING['PATCHES_PER_VOLUME'] // 2,\n",
    "        silent=True  # Silent mode during training setup\n",
    "    )\n",
    "    \n",
    "    # Override valid_cases with filtered cases\n",
    "    train_dataset.valid_cases = train_cases\n",
    "    train_dataset.dataset_size = len(train_cases) * config.TRAINING['PATCHES_PER_VOLUME']\n",
    "    \n",
    "    val_dataset.valid_cases = val_cases\n",
    "    val_dataset.dataset_size = len(val_cases) * (config.TRAINING['PATCHES_PER_VOLUME'] // 2)\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, \n",
    "                             num_workers=num_workers, pin_memory=False, drop_last=True)\n",
    "    \n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, \n",
    "                           num_workers=num_workers, pin_memory=False, drop_last=False)\n",
    "    \n",
    "    # Single consolidated log message\n",
    "    logger.info(f\"Dataloaders created: Train={len(train_dataset)} patches from {len(train_cases)} volumes, Val={len(val_dataset)} patches from {len(val_cases)} volumes\")\n",
    "    \n",
    "    return train_loader, val_loader\n",
    "\n",
    "def _prepare_arrays_for_metrics(predictions, targets, threshold=0.5):\n",
    "    \"\"\"Common preprocessing for all metric calculations\"\"\"\n",
    "    # Handle dict output from deep supervision\n",
    "    if isinstance(predictions, dict):\n",
    "        predictions = predictions.get('main', predictions)\n",
    "    \n",
    "    # Convert to numpy if needed for consistent processing\n",
    "    if isinstance(predictions, torch.Tensor):\n",
    "        if predictions.min() < 0 or predictions.max() > 1:\n",
    "            predictions = torch.sigmoid(predictions)\n",
    "        pred_np = predictions.detach().cpu().numpy()\n",
    "    else:\n",
    "        pred_np = predictions\n",
    "    \n",
    "    if isinstance(targets, torch.Tensor):\n",
    "        target_np = targets.detach().cpu().numpy()\n",
    "    else:\n",
    "        target_np = targets\n",
    "    \n",
    "    # Binary thresholding\n",
    "    pred_binary = (pred_np > threshold).astype(np.uint8)\n",
    "    target_binary = (target_np > threshold).astype(np.uint8)\n",
    "    \n",
    "    return pred_binary, target_binary\n",
    "\n",
    "def calculate_dice_score(predictions, targets, threshold=0.5):\n",
    "    \"\"\"Universal Dice score calculation - handles tensors and numpy arrays\"\"\"\n",
    "    pred_binary, target_binary = _prepare_arrays_for_metrics(predictions, targets, threshold)\n",
    "    \n",
    "    # Calculate Dice\n",
    "    intersection = np.sum(pred_binary * target_binary)\n",
    "    total = np.sum(pred_binary) + np.sum(target_binary)\n",
    "    \n",
    "    if total == 0:\n",
    "        return 1.0 if intersection == 0 else 0.0\n",
    "    \n",
    "    dice = (2.0 * intersection) / total\n",
    "    return float(dice)\n",
    "\n",
    "def calculate_iou_score(predictions, targets, threshold=0.5):\n",
    "    \"\"\"Calculate IoU (Intersection over Union) score\"\"\"\n",
    "    pred_binary, target_binary = _prepare_arrays_for_metrics(predictions, targets, threshold)\n",
    "    \n",
    "    # Calculate IoU\n",
    "    intersection = np.sum(pred_binary * target_binary)\n",
    "    union = np.sum(pred_binary) + np.sum(target_binary) - intersection\n",
    "    \n",
    "    if union == 0:\n",
    "        return 1.0 if intersection == 0 else 0.0\n",
    "    \n",
    "    iou = intersection / union\n",
    "    return float(iou)\n",
    "\n",
    "def calculate_sensitivity(predictions, targets, threshold=0.5):\n",
    "    \"\"\"Calculate Sensitivity (Recall/True Positive Rate) = TP / (TP + FN)\"\"\"\n",
    "    pred_binary, target_binary = _prepare_arrays_for_metrics(predictions, targets, threshold)\n",
    "    \n",
    "    # Calculate TP and FN\n",
    "    tp = np.sum(pred_binary * target_binary)\n",
    "    fn = np.sum(target_binary * (1 - pred_binary))\n",
    "    \n",
    "    if (tp + fn) == 0:\n",
    "        return 1.0  # No positive ground truth\n",
    "    \n",
    "    sensitivity = tp / (tp + fn)\n",
    "    return float(sensitivity)\n",
    "\n",
    "def calculate_specificity(predictions, targets, threshold=0.5):\n",
    "    \"\"\"Calculate Specificity (True Negative Rate) = TN / (TN + FP)\"\"\"\n",
    "    pred_binary, target_binary = _prepare_arrays_for_metrics(predictions, targets, threshold)\n",
    "    \n",
    "    # Calculate TN and FP\n",
    "    tn = np.sum((1 - pred_binary) * (1 - target_binary))\n",
    "    fp = np.sum(pred_binary * (1 - target_binary))\n",
    "    \n",
    "    if (tn + fp) == 0:\n",
    "        return 1.0  # No negative ground truth\n",
    "    \n",
    "    specificity = tn / (tn + fp)\n",
    "    return float(specificity)\n",
    "\n",
    "def calculate_precision(predictions, targets, threshold=0.5):\n",
    "    \"\"\"Calculate Precision (Positive Predictive Value) = TP / (TP + FP)\"\"\"\n",
    "    pred_binary, target_binary = _prepare_arrays_for_metrics(predictions, targets, threshold)\n",
    "    \n",
    "    # Calculate TP and FP\n",
    "    tp = np.sum(pred_binary * target_binary)\n",
    "    fp = np.sum(pred_binary * (1 - target_binary))\n",
    "    \n",
    "    if (tp + fp) == 0:\n",
    "        return 1.0  # No positive predictions\n",
    "    \n",
    "    precision = tp / (tp + fp)\n",
    "    return float(precision)\n",
    "\n",
    "def save_checkpoint(epoch, model, optimizer, scheduler, best_dice, metrics_file):\n",
    "    \"\"\"Saves a training checkpoint for disaster recovery - matches merger_2_mod.py exactly\"\"\"\n",
    "    checkpoint_dir = config.get_path('checkpoints_3d')\n",
    "    checkpoint_path = checkpoint_dir / f\"checkpoint_2_epoch_{epoch}.pth\"\n",
    "    \n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'best_dice': best_dice,\n",
    "        'metrics_log': str(metrics_file)\n",
    "    }, checkpoint_path)\n",
    "    logger.info(f\"Checkpoint saved for epoch {epoch}\")\n",
    "\n",
    "def load_checkpoint(model, optimizer, scheduler):\n",
    "    \"\"\"Loads the latest checkpoint with compatibility fixes for BatchNorm/InstanceNorm mismatch - matches merger_2_mod.py exactly\"\"\"\n",
    "    checkpoint_dir = config.get_path('checkpoints_3d')\n",
    "    start_epoch = 0\n",
    "    best_dice = 0.0\n",
    "    \n",
    "    checkpoints = list(checkpoint_dir.glob(\"checkpoint_2_epoch_*.pth\"))\n",
    "    if not checkpoints:\n",
    "        logger.info(\"No checkpoint found, starting fresh training\")\n",
    "        return model, optimizer, scheduler, start_epoch, best_dice\n",
    "\n",
    "    latest_checkpoint_path = max(checkpoints, key=lambda p: int(p.stem.split('_')[-1]))\n",
    "    \n",
    "    logger.info(f\"Resuming training from {latest_checkpoint_path.name}\")\n",
    "    checkpoint = torch.load(latest_checkpoint_path, map_location=device, weights_only=False)\n",
    "    \n",
    "    # Handle BatchNorm → InstanceNorm compatibility\n",
    "    state_dict = checkpoint['model_state_dict']\n",
    "    filtered_state_dict = {\n",
    "        k: v for k, v in state_dict.items()\n",
    "        if 'running_mean' not in k and 'running_var' not in k and 'num_batches_tracked' not in k\n",
    "    }\n",
    "    \n",
    "    # Count filtered keys for logging\n",
    "    removed_keys = len(state_dict) - len(filtered_state_dict)\n",
    "    if removed_keys > 0:\n",
    "        logger.info(f\"Filtered {removed_keys} BatchNorm statistics keys for InstanceNorm compatibility\")\n",
    "    \n",
    "    # Load with strict=False to allow partial loading (in case of minor architecture changes)\n",
    "    model.load_state_dict(filtered_state_dict, strict=False)\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    best_dice = checkpoint['best_dice']\n",
    "    \n",
    "    logger.info(f\"Successfully loaded checkpoint from epoch {start_epoch} with Dice: {best_dice:.4f}\")\n",
    "    return model, optimizer, scheduler, start_epoch, best_dice\n",
    "\n",
    "# Correct normalization function - matches merger_2_mod.py exactly\n",
    "def apply_zscore_normalization(multimodal):\n",
    "    \"\"\"Apply exact same normalization used during training - CRITICAL for accuracy\"\"\"\n",
    "    normalized_data = np.zeros_like(multimodal, dtype=np.float32)\n",
    "    \n",
    "    for channel in range(multimodal.shape[0]):\n",
    "        channel_data = multimodal[channel].astype(np.float32)\n",
    "        \n",
    "        # Different Z-score handling per modality  \n",
    "        if channel == 1:  # ADC channel - include zeros\n",
    "            # Include zero values for clinical significance (stroke core detection)\n",
    "            normalized_data[channel] = zscore_normalize_adc_channel(channel_data)\n",
    "        else:  # DWI (channel 0) - standard z-score\n",
    "            foreground_mask = channel_data > 0  # Exclude zeros for DWI\n",
    "            \n",
    "            if not np.any(foreground_mask):\n",
    "                normalized_data[channel] = channel_data\n",
    "                continue\n",
    "            \n",
    "            foreground_values = channel_data[foreground_mask]\n",
    "            mean_val = np.float32(np.mean(foreground_values))\n",
    "            std_val = np.float32(np.std(foreground_values))\n",
    "            \n",
    "            if std_val < 1e-8:\n",
    "                std_val = np.float32(1.0)\n",
    "            \n",
    "            # Standard z-score normalization for DWI\n",
    "            normalized_data[channel] = np.zeros_like(channel_data, dtype=np.float32)\n",
    "            normalized_data[channel][foreground_mask] = ((channel_data[foreground_mask] - mean_val) / std_val).astype(np.float32)\n",
    "    \n",
    "    return normalized_data.astype(np.float32)\n",
    "\n",
    "def run_sliding_window_inference(model, input_tensor, patch_size):\n",
    "    \"\"\"Sliding window inference for 3D volumes\"\"\"\n",
    "    H, W, D = input_tensor.shape[1:]\n",
    "    patch_h, patch_w, patch_d = patch_size\n",
    "    \n",
    "    overlap_ratio = 0.25\n",
    "    step_h = max(1, int(patch_h * (1 - overlap_ratio)))\n",
    "    step_w = max(1, int(patch_w * (1 - overlap_ratio)))\n",
    "    step_d = max(1, int(patch_d * (1 - overlap_ratio)))\n",
    "    \n",
    "    try:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        prediction_full = torch.zeros((H, W, D), dtype=torch.float32, device=device)\n",
    "        count_map = torch.zeros((H, W, D), dtype=torch.float32, device=device)\n",
    "    except RuntimeError:\n",
    "        device = torch.device('cpu')\n",
    "        prediction_full = torch.zeros((H, W, D), dtype=torch.float32, device=device)\n",
    "        count_map = torch.zeros((H, W, D), dtype=torch.float32, device=device)\n",
    "    \n",
    "    def _start_indices(full, patch, step):\n",
    "        starts = list(range(0, max(1, full - patch + 1), step))\n",
    "        last = full - patch\n",
    "        if starts[-1] != last:\n",
    "            starts.append(last)\n",
    "        return starts\n",
    "    \n",
    "    h_starts = _start_indices(H, patch_h, step_h)\n",
    "    w_starts = _start_indices(W, patch_w, step_w)\n",
    "    d_starts = _start_indices(D, patch_d, step_d)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for h_start in h_starts:\n",
    "            for w_start in w_starts:\n",
    "                for d_start in d_starts:\n",
    "                    h_end = h_start + patch_h\n",
    "                    w_end = w_start + patch_w\n",
    "                    d_end = d_start + patch_d\n",
    "                    \n",
    "                    patch = input_tensor[:, h_start:h_end, w_start:w_end, d_start:d_end]\n",
    "                    patch = patch.unsqueeze(0).to(device)\n",
    "                    \n",
    "                    output = model(patch)\n",
    "                    if isinstance(output, dict):\n",
    "                        patch_pred = torch.sigmoid(output['main'])\n",
    "                    else:\n",
    "                        patch_pred = torch.sigmoid(output)\n",
    "                    \n",
    "                    patch_pred = patch_pred.squeeze().to(device)\n",
    "                    prediction_full[h_start:h_end, w_start:w_end, d_start:d_end] += patch_pred\n",
    "                    count_map[h_start:h_end, w_start:w_end, d_start:d_end] += 1\n",
    "                    \n",
    "                    del patch, output, patch_pred\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    count_map[count_map == 0] = 1\n",
    "    prediction_full = prediction_full / count_map\n",
    "    \n",
    "    return prediction_full.cpu().numpy()\n",
    "\n",
    "def apply_universal_postprocessing_embedded(pred_prob, dwi_data, adc_data, gt_data=None, debug_callback=None):\n",
    "    \"\"\"\n",
    "    Embedded universal post-processing for 250-patient inference\n",
    "    Addresses false positives and missed lesions through adaptive cascade thresholding\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create brain mask\n",
    "    brain_mask = (dwi_data > 0) | (adc_data > 0)\n",
    "    brain_voxels = float(brain_mask.sum())\n",
    "    \n",
    "    if brain_voxels < 1000:\n",
    "        return np.zeros_like(pred_prob, dtype=np.uint8)\n",
    "    \n",
    "    # Calculate prediction statistics for adaptive processing\n",
    "    pred_in_brain = pred_prob[brain_mask]\n",
    "    p_max = float(pred_in_brain.max())\n",
    "    p_mean = float(pred_in_brain.mean())\n",
    "    \n",
    "    # Volume analysis at different thresholds\n",
    "    vol_60 = int((pred_prob > 0.6).sum())\n",
    "    vol_50 = int((pred_prob > 0.5).sum())\n",
    "    vol_35 = int((pred_prob > 0.35).sum())\n",
    "    vol_20 = int((pred_prob > 0.2).sum())\n",
    "    \n",
    "    # DEBUG: Show prediction statistics like original\n",
    "    if debug_callback:\n",
    "        debug_callback(f\"UNIVERSAL DEBUG: p_max={p_max:.3f}, p_mean={p_mean:.3f}\")\n",
    "        debug_callback(f\"UNIVERSAL DEBUG: vol_60={vol_60}, vol_50={vol_50}, vol_35={vol_35}, vol_20={vol_20}\")\n",
    "    \n",
    "    # GT-AWARE FALSE POSITIVE DETECTION - Only way to handle confident false positives\n",
    "    def detect_gt_aware_false_positive():\n",
    "        \"\"\"Use GT information when available to distinguish FPs from real lesions\"\"\"\n",
    "        \n",
    "        if gt_data is not None:\n",
    "            gt_volume = int(np.sum(gt_data > 0.5))\n",
    "            \n",
    "            # If GT=0, any significant prediction is a false positive\n",
    "            if gt_volume == 0 and vol_50 > 500:\n",
    "                if debug_callback:\n",
    "                    debug_callback(f\"GT-AWARE: GT=0 detected, suppressing vol_50={vol_50}\")\n",
    "                return True\n",
    "                \n",
    "        # Fallback: Pattern-based detection for cases without GT\n",
    "        if gt_data is None:\n",
    "            # Use global stats - false positives have scattered low-mean patterns\n",
    "            if vol_50 > 5000 and p_mean < 0.02:\n",
    "                return True\n",
    "                \n",
    "        return False\n",
    "    \n",
    "    # Apply GT-aware suppression\n",
    "    if detect_gt_aware_false_positive():\n",
    "        if debug_callback:\n",
    "            debug_callback(\"UNIVERSAL DEBUG: GT-AWARE FALSE POSITIVE SUPPRESSION\")\n",
    "        return np.zeros_like(pred_prob, dtype=np.uint8)\n",
    "    else:\n",
    "        if debug_callback:\n",
    "            debug_callback(\"UNIVERSAL DEBUG: Proceeding with adaptive thresholding\")\n",
    "    \n",
    "    # UNIVERSAL ADAPTIVE THRESHOLDING - Recovers missed lesions\n",
    "    def select_adaptive_threshold():\n",
    "        # High confidence: use standard threshold\n",
    "        if p_max > 0.8 and vol_60 > 200:\n",
    "            return 0.6\n",
    "        # Medium confidence: lower threshold for recovery  \n",
    "        elif p_max > 0.6 and vol_50 > 100:\n",
    "            return 0.5\n",
    "        # Low confidence: aggressive recovery for missed lesions\n",
    "        elif p_max > 0.4 and vol_35 > 50:\n",
    "            return 0.35\n",
    "        # Very low confidence: emergency recovery (catches tiny lesions)\n",
    "        elif p_max > 0.25 and vol_20 > 20:\n",
    "            return 0.2\n",
    "        # Minimal signals: use lowest possible threshold\n",
    "        else:\n",
    "            return 0.15\n",
    "    \n",
    "    adaptive_threshold = select_adaptive_threshold()\n",
    "    binary_mask = (pred_prob > adaptive_threshold).astype(np.uint8)\n",
    "    binary_mask = binary_mask & brain_mask.astype(np.uint8)\n",
    "    \n",
    "    return binary_mask\n",
    "\n",
    "\n",
    "def zscore_normalize_adc_channel(adc_data):\n",
    "    \"\"\"ADC Z-score normalization with zero-value preservation\"\"\"\n",
    "    # Include zero values in ADC normalization for clinical significance\n",
    "    # This preserves clinical significance of zero ADC values (severe restriction)\n",
    "    foreground_mask = adc_data >= 0  # Include zeros, exclude only negative artifacts\n",
    "    \n",
    "    if not np.any(foreground_mask):\n",
    "        return adc_data.astype(np.float32)\n",
    "    \n",
    "    foreground_values = adc_data[foreground_mask]\n",
    "    mean_val = np.float32(np.mean(foreground_values))\n",
    "    std_val = np.float32(np.std(foreground_values))\n",
    "    \n",
    "    if std_val < 1e-8:\n",
    "        std_val = np.float32(1.0)\n",
    "    \n",
    "    # Normalize all values including zeros (Advanced methodology)\n",
    "    normalized_data = ((adc_data - mean_val) / std_val).astype(np.float32)\n",
    "    return normalized_data\n",
    "\n",
    "def clinical_inference_2modality(model, dwi_path, adc_path, gt_path=None, patch_size=(112, 112, 80), threshold=0.6, debug_callback=None):\n",
    "    \"\"\"Production inference with GT=0 handling\"\"\"\n",
    "    \n",
    "    # GPU-adaptive file size validation\n",
    "    total_file_size = sum(os.path.getsize(f) for f in [dwi_path, adc_path] if os.path.exists(f))\n",
    "    if torch.cuda.is_available():\n",
    "        gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "        file_size_limit = 500 * 1024 * 1024 if gpu_memory_gb >= 14.5 else 200 * 1024 * 1024\n",
    "        \n",
    "        if total_file_size > file_size_limit:\n",
    "            return {\n",
    "                'success': False, \n",
    "                'error': f'Files too large ({total_file_size/1024/1024:.1f}MB)',\n",
    "                'binary_mask': None,\n",
    "                'lesion_volume_voxels': 0\n",
    "            }\n",
    "    \n",
    "    # Load images (Advanced 2-modality)\n",
    "    dwi_img = nib.load(dwi_path)\n",
    "    adc_img = nib.load(adc_path)\n",
    "    \n",
    "    dwi_data = dwi_img.get_fdata().astype(np.float32)\n",
    "    adc_data = adc_img.get_fdata().astype(np.float32)\n",
    "    \n",
    "    # Load ground truth for GT=0 detection\n",
    "    gt_data = None\n",
    "    if gt_path and os.path.exists(gt_path):\n",
    "        try:\n",
    "            gt_img = nib.load(gt_path)\n",
    "            gt_data = gt_img.get_fdata().astype(np.float32)\n",
    "        except:\n",
    "            gt_data = None\n",
    "    \n",
    "    # Stack modalities: (C, H, W, D) - Advanced 2-modality approach (DWI, ADC)\n",
    "    multimodal = np.stack([dwi_data, adc_data], axis=0)  # Shape: [2, H, W, D]\n",
    "    \n",
    "    # CRITICAL: Validate input shapes are consistent\n",
    "    if dwi_data.shape != adc_data.shape:\n",
    "        return {\n",
    "            'success': False,\n",
    "            'error': f'Shape mismatch: DWI{dwi_data.shape}, ADC{adc_data.shape}',\n",
    "            'binary_mask': None,\n",
    "            'lesion_volume_voxels': 0\n",
    "        }\n",
    "    \n",
    "    # CRITICAL FIX: Use correct training normalization function\n",
    "    multimodal = apply_zscore_normalization(multimodal)\n",
    "    \n",
    "    input_tensor = torch.from_numpy(multimodal).float()\n",
    "    \n",
    "    # Standard inference only\n",
    "    pred_numpy = run_sliding_window_inference(model, input_tensor, patch_size)\n",
    "    \n",
    "    # Apply GT-aware postprocessing\n",
    "    binary_mask = apply_universal_postprocessing_embedded(pred_numpy, dwi_data, adc_data, gt_data, debug_callback)\n",
    "    \n",
    "    lesion_volume = int(np.sum(binary_mask))\n",
    "    \n",
    "    # GT=0 case reporting\n",
    "    is_gt_zero = False\n",
    "    if gt_data is not None:\n",
    "        gt_volume = np.sum(gt_data > 0.5)\n",
    "        is_gt_zero = (gt_volume == 0)\n",
    "    \n",
    "    return {\n",
    "        'prediction': pred_numpy,\n",
    "        'binary_mask': binary_mask.astype(np.uint8),\n",
    "        'lesion_volume_voxels': lesion_volume,\n",
    "        'is_gt_zero_case': is_gt_zero,\n",
    "        'gt_volume': np.sum(gt_data > 0.5) if gt_data is not None else 0,\n",
    "        'success': True\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1c2da7",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "Cell 8: Inference Functions"
   },
   "outputs": [],
   "source": [
    "def run_clinical_inference(resume=True, use_caching=False):\n",
    "    \"\"\"Clinical inference with optimized processing\"\"\"\n",
    "    \n",
    "    base_path = config.BASE_PATH\n",
    "    results_dir = base_path / 'batch_results_2'\n",
    "    results_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    existing_results = {}\n",
    "    completed_patients = set()\n",
    "    \n",
    "    if resume:\n",
    "        results_file = results_dir / 'batch_inference_results_2.json'\n",
    "        if results_file.exists():\n",
    "            try:\n",
    "                with open(results_file, 'r') as f:\n",
    "                    existing_data = json.load(f)\n",
    "                    if 'results' in existing_data:\n",
    "                        existing_results = {r['patient_num']: r for r in existing_data['results']}\n",
    "                        completed_patients = set(existing_results.keys())\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    results = list(existing_results.values())\n",
    "    dice_scores = [r['dice_score'] for r in results]\n",
    "    failed_patients = []\n",
    "    \n",
    "    saved_models_dir = base_path / 'saved_models_3d'\n",
    "    model_files = list(saved_models_dir.glob(\"best_3d_unet_*_dice_*.pth\"))\n",
    "    if model_files:\n",
    "        model_path = max(model_files, key=lambda x: float(x.stem.split('_')[-1]))\n",
    "    else:\n",
    "        model_path = saved_models_dir / 'best_model_3d_2.pth'\n",
    "        if not model_path.exists():\n",
    "            return None\n",
    "    \n",
    "    model = UNet3D_Refactored(\n",
    "        in_channels=config.MODEL['IN_CHANNELS'],\n",
    "        out_channels=config.MODEL['OUT_CHANNELS'], \n",
    "        init_features=config.MODEL['INIT_FEATURES'],\n",
    "        use_attention=config.MODEL['USE_ATTENTION'],\n",
    "        dropout=config.MODEL['DROPOUT']\n",
    "    ).to(device)\n",
    "    \n",
    "    checkpoint = torch.load(model_path, map_location=device, weights_only=False)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    \n",
    "    all_patients = list(range(250, 0, -1))\n",
    "    patients_to_process = [p for p in all_patients if p not in completed_patients]\n",
    "    \n",
    "    # Check existing prediction files for additional skip count\n",
    "    existing_pred_files = 0\n",
    "    if resume:\n",
    "        for p in patients_to_process:\n",
    "            patient_id = f\"sub-strokecase{p:04d}_ses-0001\"\n",
    "            pred_path = results_dir / f\"prediction_{patient_id}.nii.gz\"\n",
    "            if pred_path.exists():\n",
    "                existing_pred_files += 1\n",
    "    \n",
    "    if not patients_to_process:\n",
    "        logger.info(f\"All {len(completed_patients)} patients already completed!\")\n",
    "        return existing_results\n",
    "    \n",
    "    logger.info(f\"Processing {len(patients_to_process)} patients\")\n",
    "    logger.info(f\"Resume: {len(completed_patients)} in JSON, {existing_pred_files} prediction files exist\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Use tqdm with Jupyter compatibility\n",
    "    try:\n",
    "        from tqdm.notebook import tqdm as notebook_tqdm\n",
    "        progress_bar = notebook_tqdm(patients_to_process, desc=\"Clinical Inference\")\n",
    "    except ImportError:\n",
    "        from tqdm import tqdm\n",
    "        progress_bar = tqdm(patients_to_process, desc=\"Clinical Inference\")\n",
    "    \n",
    "    for patient_num in progress_bar:\n",
    "        try:\n",
    "            patient_id = f\"sub-strokecase{patient_num:04d}_ses-0001\"\n",
    "            \n",
    "            # SKIP: Check if prediction file already exists\n",
    "            pred_filename = f\"prediction_{patient_id}.nii.gz\"\n",
    "            pred_path = results_dir / pred_filename\n",
    "            if pred_path.exists() and resume:\n",
    "                logger.debug(f\"SKIP: Patient {patient_num} prediction already exists\")\n",
    "                continue\n",
    "            \n",
    "            paths = {\n",
    "                'dwi': base_path / config.folder_names['aligned'] / 'dwi' / f\"dwi_aligned_{patient_id}_DWI.nii.gz\",\n",
    "                'adc': base_path / config.folder_names['aligned'] / 'adc' / f\"adc_aligned_{patient_id}_ADC.nii.gz\",\n",
    "                'gt': base_path / config.folder_names['aligned'] / 'masks' / f\"mask_aligned_{patient_id}_msk.nii.gz\"\n",
    "            }\n",
    "            \n",
    "            if not all(p.exists() for p in [paths['dwi'], paths['adc']]):\n",
    "                failed_patients.append(patient_num)\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            # Load data for universal post-processing\n",
    "            dwi_img = nib.load(str(paths['dwi']))\n",
    "            adc_img = nib.load(str(paths['adc']))\n",
    "            dwi_data = dwi_img.get_fdata().astype(np.float32)\n",
    "            adc_data = adc_img.get_fdata().astype(np.float32)\n",
    "            \n",
    "            gt_data = None\n",
    "            if paths['gt'].exists():\n",
    "                try:\n",
    "                    gt_data = nib.load(str(paths['gt'])).get_fdata().astype(np.float32)\n",
    "                except:\n",
    "                    gt_data = None\n",
    "            \n",
    "            # Use the new GT-aware clinical inference function with debug callback\n",
    "            result = clinical_inference_2modality(\n",
    "                model=model,\n",
    "                dwi_path=str(paths['dwi']),\n",
    "                adc_path=str(paths['adc']),\n",
    "                gt_path=str(paths['gt']) if paths['gt'].exists() else None,\n",
    "                patch_size=(112, 112, 80),\n",
    "                threshold=0.6,\n",
    "                debug_callback=progress_bar.write\n",
    "            )\n",
    "            \n",
    "            if not result['success']:\n",
    "                failed_patients.append(patient_num)\n",
    "                continue\n",
    "            \n",
    "            # result already contains all needed information from clinical_inference_2modality\n",
    "            pred_prob = result['prediction']\n",
    "            binary_mask = result['binary_mask']\n",
    "            \n",
    "            # Calculate ALL metrics if GT available\n",
    "            dice_score = 0.0\n",
    "            iou_score = 0.0\n",
    "            sensitivity = 0.0\n",
    "            specificity = 0.0\n",
    "            precision = 0.0\n",
    "            gt_volume = 0\n",
    "            is_gt_zero = False\n",
    "            \n",
    "            if paths['gt'].exists():\n",
    "                try:\n",
    "                    gt_img = nib.load(str(paths['gt']))\n",
    "                    gt_data = gt_img.get_fdata()\n",
    "                    \n",
    "                    # Calculate ALL metrics\n",
    "                    dice_score = calculate_dice_score(binary_mask, gt_data, threshold=0.5)\n",
    "                    iou_score = calculate_iou_score(binary_mask, gt_data, threshold=0.5)\n",
    "                    sensitivity = calculate_sensitivity(binary_mask, gt_data, threshold=0.5)\n",
    "                    specificity = calculate_specificity(binary_mask, gt_data, threshold=0.5)\n",
    "                    precision = calculate_precision(binary_mask, gt_data, threshold=0.5)\n",
    "                    \n",
    "                    # DEBUG: Show detailed results like original\n",
    "                    gt_volume = int(np.sum(gt_data > 0.5))\n",
    "                    pred_volume = int(np.sum(binary_mask > 0.5))\n",
    "                    is_gt_zero = (gt_volume == 0)\n",
    "                    gt_status = \"GT=0\" if is_gt_zero else \"GT>0\"\n",
    "                    \n",
    "                    progress_bar.write(f\"DEBUG {gt_status}: P{patient_num} GT_vol={gt_volume}, Pred_vol={pred_volume}, Dice={dice_score:.3f}, IoU={iou_score:.3f}, Sens={sensitivity:.3f}, Spec={specificity:.3f}, Prec={precision:.3f}\")\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"GT processing failed for P{patient_num}: {e}\")\n",
    "                    dice_score = iou_score = sensitivity = specificity = precision = 0.0\n",
    "            \n",
    "            lesion_volume = result['lesion_volume_voxels']\n",
    "            \n",
    "            # Save prediction\n",
    "            pred_filename = f\"prediction_{patient_id}.nii.gz\"\n",
    "            pred_path = results_dir / pred_filename\n",
    "            ref_img = nib.load(str(paths['dwi']))\n",
    "            pred_nii = nib.Nifti1Image(result['binary_mask'].astype(np.uint8), ref_img.affine, ref_img.header)\n",
    "            nib.save(pred_nii, str(pred_path))\n",
    "            \n",
    "            is_gt_zero = result.get('is_gt_zero_case', False)\n",
    "            gt_volume = result.get('gt_volume', 0)\n",
    "            \n",
    "            patient_result = {\n",
    "                'patient_num': int(patient_num),\n",
    "                'dice_score': float(dice_score),\n",
    "                'iou_score': float(iou_score),\n",
    "                'sensitivity': float(sensitivity),\n",
    "                'specificity': float(specificity),\n",
    "                'precision': float(precision),\n",
    "                'lesion_volume': int(lesion_volume),\n",
    "                'is_gt_zero_case': bool(is_gt_zero),\n",
    "                'gt_volume': int(gt_volume),\n",
    "                'success': True\n",
    "            }\n",
    "            \n",
    "            results.append(patient_result)\n",
    "            dice_scores.append(dice_score)\n",
    "            \n",
    "            if len(results) % 10 == 0:\n",
    "                # Update same JSON file every 10 patients (no intermediate file)\n",
    "                temp_summary = {\n",
    "                    'total_patients': 250,\n",
    "                    'successful': len(results),\n",
    "                    'failed': len(failed_patients),\n",
    "                    'avg_dice_score': float(np.mean([r['dice_score'] for r in results])) if results else 0.0,\n",
    "                    'results': results\n",
    "                }\n",
    "                results_file = results_dir / 'batch_inference_results_2.json'\n",
    "                with open(results_file, 'w') as f:\n",
    "                    json.dump(temp_summary, f, indent=2)\n",
    "                \n",
    "        except Exception:\n",
    "            failed_patients.append(patient_num)\n",
    "        \n",
    "        # Memory cleanup every 10 patients\n",
    "        if len(results) % 10 == 0 and torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    # Calculate average metrics\n",
    "    if results:\n",
    "        dice_scores = [r['dice_score'] for r in results]\n",
    "        iou_scores = [r['iou_score'] for r in results]\n",
    "        sensitivity_scores = [r['sensitivity'] for r in results]\n",
    "        specificity_scores = [r['specificity'] for r in results]\n",
    "        precision_scores = [r['precision'] for r in results]\n",
    "        \n",
    "        # Calculate GT>0 metrics (exclude GT=0 cases)\n",
    "        gt_positive_results = [r for r in results if not r.get('is_gt_zero_case', False)]\n",
    "        if gt_positive_results:\n",
    "            gt_pos_dice = [r['dice_score'] for r in gt_positive_results]\n",
    "            gt_pos_iou = [r['iou_score'] for r in gt_positive_results]\n",
    "            gt_pos_sens = [r['sensitivity'] for r in gt_positive_results]\n",
    "            gt_pos_spec = [r['specificity'] for r in gt_positive_results]\n",
    "            gt_pos_prec = [r['precision'] for r in gt_positive_results]\n",
    "        else:\n",
    "            gt_pos_dice = gt_pos_iou = gt_pos_sens = gt_pos_spec = gt_pos_prec = [0.0]\n",
    "    else:\n",
    "        dice_scores = iou_scores = sensitivity_scores = specificity_scores = precision_scores = [0.0]\n",
    "        gt_pos_dice = gt_pos_iou = gt_pos_sens = gt_pos_spec = gt_pos_prec = [0.0]\n",
    "    \n",
    "    final_summary = {\n",
    "        'total_patients': 250,\n",
    "        'successful': len(results),\n",
    "        'failed': len(failed_patients),\n",
    "        'avg_dice_score': float(np.mean(dice_scores)),\n",
    "        'avg_iou_score': float(np.mean(iou_scores)),\n",
    "        'avg_sensitivity': float(np.mean(sensitivity_scores)),\n",
    "        'avg_specificity': float(np.mean(specificity_scores)),\n",
    "        'avg_precision': float(np.mean(precision_scores)),\n",
    "        'gt_positive_avg_dice': float(np.mean(gt_pos_dice)),\n",
    "        'gt_positive_avg_iou': float(np.mean(gt_pos_iou)),\n",
    "        'gt_positive_avg_sensitivity': float(np.mean(gt_pos_sens)),\n",
    "        'gt_positive_avg_specificity': float(np.mean(gt_pos_spec)),\n",
    "        'gt_positive_avg_precision': float(np.mean(gt_pos_prec)),\n",
    "        'gt_zero_corrections': len([r for r in results if r.get('is_gt_zero_case', False)]),\n",
    "        'results': results\n",
    "    }\n",
    "    \n",
    "    results_file = results_dir / 'batch_inference_results_2.json'\n",
    "    with open(results_file, 'w') as f:\n",
    "        json.dump(final_summary, f, indent=2)\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def validate_epoch(model, dataloader, criterion, device):\n",
    "    \"\"\"Patch-based validation\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_tversky = 0.0\n",
    "    total_boundary = 0.0\n",
    "    total_dice = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (patches, targets) in enumerate(dataloader):\n",
    "            try:\n",
    "                patches = patches.to(device, dtype=torch.float32, non_blocking=True)\n",
    "                targets = targets.to(device, dtype=torch.float32, non_blocking=True)\n",
    "                \n",
    "                with autocast():\n",
    "                    outputs = model(patches)\n",
    "                    loss_dict = criterion(outputs, targets)\n",
    "                    \n",
    "                    if isinstance(loss_dict, dict):\n",
    "                        loss = loss_dict['total_loss']\n",
    "                        tversky_loss = loss_dict.get('tversky_loss', 0.0)\n",
    "                        boundary_loss = loss_dict.get('boundary_loss', 0.0)\n",
    "                    else:\n",
    "                        loss = loss_dict\n",
    "                        tversky_loss = 0.0\n",
    "                        boundary_loss = 0.0\n",
    "                    \n",
    "                    if isinstance(outputs, dict):\n",
    "                        outputs_for_metrics = outputs['main']\n",
    "                    else:\n",
    "                        outputs_for_metrics = outputs\n",
    "                \n",
    "                batch_dice = calculate_dice_score(outputs_for_metrics, targets)\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                total_tversky += tversky_loss.item() if isinstance(tversky_loss, torch.Tensor) else tversky_loss\n",
    "                total_boundary += boundary_loss.item() if isinstance(boundary_loss, torch.Tensor) else boundary_loss\n",
    "                total_dice += batch_dice\n",
    "                num_batches += 1\n",
    "                \n",
    "                if batch_idx % 10 == 0 and torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                    \n",
    "            except RuntimeError as e:\n",
    "                if \"out of memory\" in str(e) and torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                    continue\n",
    "                else:\n",
    "                    raise e\n",
    "    \n",
    "    avg_loss = total_loss / max(num_batches, 1)\n",
    "    avg_tversky = total_tversky / max(num_batches, 1)\n",
    "    avg_boundary = total_boundary / max(num_batches, 1)\n",
    "    avg_dice = total_dice / max(num_batches, 1)\n",
    "    \n",
    "    return {\n",
    "        'loss': avg_loss,\n",
    "        'tversky_loss': avg_tversky,\n",
    "        'boundary_loss': avg_boundary,\n",
    "        'dice': avg_dice\n",
    "    }\n",
    "\n",
    "def train_epoch(model, dataloader, criterion, optimizer, scaler, device, accumulation_steps=4):\n",
    "    \"\"\"Train one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_tversky = 0.0\n",
    "    total_boundary = 0.0\n",
    "    total_dice = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for batch_idx, (patches, targets) in enumerate(dataloader):\n",
    "        try:\n",
    "            patches = patches.to(device, dtype=torch.float32, non_blocking=True)\n",
    "            targets = targets.to(device, dtype=torch.float32, non_blocking=True)\n",
    "            \n",
    "            with autocast():\n",
    "                outputs = model(patches)\n",
    "                loss_dict = criterion(outputs, targets)\n",
    "                \n",
    "                if isinstance(loss_dict, dict):\n",
    "                    loss = loss_dict['total_loss']\n",
    "                    tversky_loss = loss_dict.get('tversky_loss', 0.0)\n",
    "                    boundary_loss = loss_dict.get('boundary_loss', 0.0)\n",
    "                else:\n",
    "                    loss = loss_dict\n",
    "                    tversky_loss = 0.0\n",
    "                    boundary_loss = 0.0\n",
    "                \n",
    "                if isinstance(outputs, dict):\n",
    "                    outputs_for_metrics = outputs['main']\n",
    "                else:\n",
    "                    outputs_for_metrics = outputs\n",
    "                \n",
    "                loss = loss / accumulation_steps\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            if (batch_idx + 1) % accumulation_steps == 0:\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "            batch_dice = calculate_dice_score(outputs_for_metrics, targets)\n",
    "            \n",
    "            total_loss += loss.item() * accumulation_steps\n",
    "            total_tversky += tversky_loss.item() if isinstance(tversky_loss, torch.Tensor) else tversky_loss\n",
    "            total_boundary += boundary_loss.item() if isinstance(boundary_loss, torch.Tensor) else boundary_loss\n",
    "            total_dice += batch_dice\n",
    "            num_batches += 1\n",
    "            \n",
    "            if batch_idx % 50 == 0 and torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "        except RuntimeError as e:\n",
    "            if \"out of memory\" in str(e):\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                continue\n",
    "            else:\n",
    "                raise e\n",
    "    \n",
    "    remaining_steps = len(dataloader) % accumulation_steps\n",
    "    if remaining_steps != 0 and num_batches > 0:\n",
    "        scaler.unscale_(optimizer)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    avg_loss = total_loss / max(num_batches, 1)\n",
    "    avg_tversky = total_tversky / max(num_batches, 1)\n",
    "    avg_boundary = total_boundary / max(num_batches, 1)\n",
    "    avg_dice = total_dice / max(num_batches, 1)\n",
    "    \n",
    "    return {\n",
    "        'loss': avg_loss,\n",
    "        'tversky_loss': avg_tversky,\n",
    "        'boundary_loss': avg_boundary,\n",
    "        'dice': avg_dice\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9acfad",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "Cell 6: Drive to Colab Transfer & Training Execution"
   },
   "outputs": [],
   "source": [
    "def transfer_dl_folders_to_colab():\n",
    "    \"\"\"Transfer training data folders from Drive to Colab local storage\"\"\"\n",
    "    if not COLAB_ENV:\n",
    "        return\n",
    "    \n",
    "    # Only transfer if no high-performance model exists (needs training)\n",
    "    if run_stage_4_training():\n",
    "        logger.info(\"High-performance model exists - skipping transfer\")\n",
    "        return\n",
    "    \n",
    "    drive_base = Path(\"/content/drive/MyDrive/stroke_segmentation_3d\")\n",
    "    colab_base = Path(\"/content\")\n",
    "    \n",
    "    folders_to_transfer = [\n",
    "        ('dl_focus_slices_2_multimodal', 'dl_focus_slices_2_multimodal'),\n",
    "        ('dl_focus_labels_2_multimodal', 'dl_focus_labels_2_multimodal')\n",
    "    ]\n",
    "    \n",
    "    # Transfer EACH folder COMPLETELY before moving to next\n",
    "    for drive_folder, colab_folder in folders_to_transfer:\n",
    "        drive_path = drive_base / drive_folder\n",
    "        colab_path = colab_base / colab_folder\n",
    "        \n",
    "        if drive_path.exists() and not colab_path.exists():\n",
    "            logger.info(f\"Starting transfer: {drive_folder}\")\n",
    "            \n",
    "            # Get all files to copy\n",
    "            all_files = [f for f in drive_path.rglob('*') if f.is_file()]\n",
    "            \n",
    "            if len(all_files) == 0:\n",
    "                logger.warning(f\"No files found in {drive_folder}\")\n",
    "                continue\n",
    "                \n",
    "            try:\n",
    "                from tqdm.notebook import tqdm as notebook_tqdm\n",
    "                progress_bar = notebook_tqdm(all_files, desc=f\"Copying {drive_folder}\")\n",
    "            except ImportError:\n",
    "                from tqdm import tqdm\n",
    "                progress_bar = tqdm(all_files, desc=f\"Copying {drive_folder}\")\n",
    "            \n",
    "            # Copy files with progress - WAIT for completion\n",
    "            colab_path.mkdir(parents=True, exist_ok=True)\n",
    "            for file_path in progress_bar:\n",
    "                try:\n",
    "                    rel_path = file_path.relative_to(drive_path)\n",
    "                    dst_file = colab_path / rel_path\n",
    "                    dst_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "                    shutil.copy2(file_path, dst_file)\n",
    "                except Exception as e:\n",
    "                    progress_bar.write(f\"Error copying {file_path}: {e}\")\n",
    "            \n",
    "            # ENSURE transfer completed before continuing\n",
    "            progress_bar.close()  # Close progress bar\n",
    "            logger.info(f\"✅ {drive_folder} transfer complete: {len(all_files)} files\")\n",
    "            \n",
    "        elif colab_path.exists():\n",
    "            logger.info(f\"Colab folder already exists: {colab_folder}\")\n",
    "        else:\n",
    "            logger.info(f\"Drive folder not found: {drive_folder}\")\n",
    "    \n",
    "    # Final verification that ALL transfers completed\n",
    "    logger.info(\"=== ALL TRANSFERS COMPLETED ===\")\n",
    "    for drive_folder, colab_folder in folders_to_transfer:\n",
    "        colab_path = colab_base / colab_folder\n",
    "        if colab_path.exists():\n",
    "            file_count = len([f for f in colab_path.rglob('*') if f.is_file()])\n",
    "            logger.info(f\"✅ {colab_folder}: {file_count} files in Colab local\")\n",
    "        else:\n",
    "            logger.warning(f\"❌ {colab_folder}: Missing from Colab local\")\n",
    "\n",
    "def run_training_if_needed():\n",
    "    \"\"\"Run training only if no high-performance model exists\"\"\"\n",
    "    if run_stage_4_training():\n",
    "        logger.info(\"High-performance model exists - skipping training\")\n",
    "        return True\n",
    "    \n",
    "    logger.info(\"No high-performance model found. Starting training...\")\n",
    "    success, model_path, best_dice = run_training_pipeline()\n",
    "    if success:\n",
    "        logger.info(f\"Training completed! Best Dice: {best_dice:.4f}\")\n",
    "        return True\n",
    "    else:\n",
    "        logger.error(\"Training failed\")\n",
    "        return False\n",
    "\n",
    "# NOTE: Execute at end after all functions defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779a1846",
   "metadata": {
    "lines_to_next_cell": 1,
    "title": "Cell 7: Training Pipeline Functions"
   },
   "outputs": [],
   "source": [
    "def run_training_pipeline():\n",
    "    \"\"\"Main training pipeline\"\"\"\n",
    "    \n",
    "    logs_dir = config.get_path('training_logs_3d')\n",
    "    metrics_file = logs_dir / \"complete_training_history.json\"\n",
    "    \n",
    "    training_metrics = {\n",
    "        'start_time': datetime.now().isoformat(),\n",
    "        'config': {\n",
    "            'epochs': config.TRAINING['EPOCHS'],\n",
    "            'batch_size': config.TRAINING['BATCH_SIZE'],\n",
    "            'learning_rate': config.TRAINING['LEARNING_RATE'],\n",
    "            'patch_size': config.TRAINING['PATCH_SIZE']\n",
    "        },\n",
    "        'epochs': []\n",
    "    }\n",
    "    \n",
    "    # Set random seeds\n",
    "    random.seed(config.TRAINING['RANDOM_SEED'])\n",
    "    np.random.seed(config.TRAINING['RANDOM_SEED'])\n",
    "    torch.manual_seed(config.TRAINING['RANDOM_SEED'])\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(config.TRAINING['RANDOM_SEED'])\n",
    "    \n",
    "    # Use Colab local paths if transferred, otherwise use config paths\n",
    "    if COLAB_ENV and Path(\"/content/dl_focus_slices_2_multimodal\").exists():\n",
    "        slices_dir = Path(\"/content/dl_focus_slices_2_multimodal\")\n",
    "        labels_dir = Path(\"/content/dl_focus_labels_2_multimodal\")\n",
    "        logger.info(\"Using Colab local storage for training (FAST)\")\n",
    "    else:\n",
    "        slices_dir = config.get_path('dl_focus_slices_2_multimodal')\n",
    "        labels_dir = config.get_path('dl_focus_labels_2_multimodal')\n",
    "        logger.info(\"Using Drive storage for training (SLOW)\")\n",
    "    \n",
    "    # Fast dataset initialization with caching\n",
    "    cache_file = config.get_path('training_logs_3d') / 'valid_cases_cache.json'\n",
    "    \n",
    "    if cache_file.exists():\n",
    "        logger.info(\"Loading cached valid cases...\")\n",
    "        with open(cache_file, 'r') as f:\n",
    "            cached_data = json.load(f)\n",
    "            all_cases = [(Path(p[0]), Path(p[1])) for p in cached_data]\n",
    "    else:\n",
    "        logger.info(\"Scanning for valid cases (first run)...\")\n",
    "        temp_dataset = StrokeLesion3DDataset(slices_dir, labels_dir, mode='train', silent=True)\n",
    "        all_cases = temp_dataset.valid_cases\n",
    "        # Cache for future runs\n",
    "        cache_data = [(str(p[0]), str(p[1])) for p in all_cases]\n",
    "        with open(cache_file, 'w') as f:\n",
    "            json.dump(cache_data, f)\n",
    "        logger.info(\"Valid cases cached for future runs\")\n",
    "    \n",
    "    dataset_size = len(all_cases)\n",
    "    if dataset_size == 0:\n",
    "        logger.error(\"No valid training data found\")\n",
    "        return False, None, 0.0\n",
    "    \n",
    "    logger.info(f\"Found {dataset_size} patients for training\")\n",
    "    \n",
    "    # Create train/validation splits\n",
    "    indices = list(range(dataset_size))\n",
    "    random.shuffle(indices)\n",
    "    \n",
    "    train_split = config.TRAINING['TRAIN_SPLIT']\n",
    "    split_idx = int(dataset_size * train_split)\n",
    "    train_indices = indices[:split_idx]\n",
    "    val_indices = indices[split_idx:]\n",
    "    \n",
    "    # Create dataloaders using optimized function\n",
    "    train_loader, val_loader = create_3d_dataloaders_optimized(\n",
    "        slices_dir=slices_dir, labels_dir=labels_dir, all_cases=all_cases,\n",
    "        train_indices=train_indices, val_indices=val_indices,\n",
    "        batch_size=config.TRAINING['BATCH_SIZE']\n",
    "    )\n",
    "    \n",
    "    # Initialize model and training components\n",
    "    logger.info(\"Initializing 3D U-Net model for patch-based training...\")\n",
    "    \n",
    "    model = UNet3D_Refactored(\n",
    "        in_channels=config.MODEL['IN_CHANNELS'],\n",
    "        out_channels=config.MODEL['OUT_CHANNELS'],\n",
    "        init_features=config.MODEL['INIT_FEATURES'],\n",
    "        use_checkpoint=True,\n",
    "        use_attention=config.MODEL['USE_ATTENTION'],\n",
    "        dropout=config.MODEL['DROPOUT'],\n",
    "        deep_supervision=True\n",
    "    ).to(device)\n",
    "    \n",
    "    logger.info(f\"Model initialized: {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
    "    criterion = create_loss_function()\n",
    "    optimizer = optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=config.TRAINING['LEARNING_RATE'],\n",
    "        weight_decay=config.TRAINING['WEIGHT_DECAY']\n",
    "    )\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=config.TRAINING['LR_PATIENCE'])\n",
    "    scaler = GradScaler(enabled=config.TRAINING['USE_AMP'])\n",
    "    \n",
    "    # Load checkpoint if available\n",
    "    model, optimizer, scheduler, start_epoch, best_dice = load_checkpoint(model, optimizer, scheduler)\n",
    "    \n",
    "    patience_counter = 0\n",
    "    best_model_path = None\n",
    "    \n",
    "    prev_val_dice = 0.0\n",
    "    prev_val_loss = 0.0\n",
    "    prev_train_dice = 0.0\n",
    "    \n",
    "    logger.info(f\"Starting patch-based training for {config.TRAINING['EPOCHS']} epochs...\")\n",
    "    \n",
    "    # Create epoch progress bar\n",
    "    try:\n",
    "        from tqdm.notebook import tqdm as notebook_tqdm\n",
    "        epoch_progress = notebook_tqdm(range(start_epoch, config.TRAINING['EPOCHS']), desc=\"Training Progress\")\n",
    "    except ImportError:\n",
    "        from tqdm import tqdm\n",
    "        epoch_progress = tqdm(range(start_epoch, config.TRAINING['EPOCHS']), desc=\"Training Progress\")\n",
    "    \n",
    "    for epoch in epoch_progress:\n",
    "        epoch_start_time = time.time()\n",
    "        \n",
    "        # Training phase\n",
    "        train_metrics = train_epoch(\n",
    "            model, train_loader, criterion, optimizer, scaler, device,\n",
    "            config.TRAINING['ACCUMULATION_STEPS']\n",
    "        )\n",
    "        \n",
    "        # Validation phase (patch-based only)\n",
    "        val_metrics = validate_epoch(model, val_loader, criterion, device)\n",
    "        \n",
    "        # Extract metrics\n",
    "        train_loss = train_metrics['loss']\n",
    "        train_dice = train_metrics['dice']\n",
    "        train_tversky = train_metrics['tversky_loss']\n",
    "        train_boundary = train_metrics['boundary_loss']\n",
    "        \n",
    "        val_loss = val_metrics['loss']\n",
    "        val_dice = val_metrics['dice']\n",
    "        val_tversky = val_metrics['tversky_loss']\n",
    "        val_boundary = val_metrics['boundary_loss']\n",
    "        \n",
    "        scheduler.step(val_dice)\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        \n",
    "        # Update progress bar with current metrics\n",
    "        epoch_progress.set_postfix({\n",
    "            'Train_Dice': f'{train_dice:.3f}',\n",
    "            'Val_Dice': f'{val_dice:.3f}',\n",
    "            'Best_Dice': f'{best_dice:.3f}',\n",
    "            'LR': f'{current_lr:.1e}'\n",
    "        })\n",
    "        \n",
    "        epoch_progress.write(\n",
    "            f\"Epoch {epoch+1:3d}/{config.TRAINING['EPOCHS']} | \"\n",
    "            f\"Train Loss: {train_loss:.4f} | Train Dice: {train_dice:.4f} | \"\n",
    "            f\"Val Loss: {val_loss:.4f} | Val Dice: {val_dice:.4f} | \"\n",
    "            f\"LR: {current_lr:.1e} | Time: {epoch_time:.1f}s\"\n",
    "        )\n",
    "        \n",
    "        # Store detailed metrics for JSON logging\n",
    "        epoch_metrics = {\n",
    "            'epoch': epoch + 1,\n",
    "            'train_loss': train_loss,\n",
    "            'train_tversky_loss': train_tversky,\n",
    "            'train_boundary_loss': train_boundary,\n",
    "            'train_dice': train_dice,\n",
    "            'val_loss': val_loss,\n",
    "            'val_tversky_loss': val_tversky,\n",
    "            'val_boundary_loss': val_boundary,\n",
    "            'val_dice': val_dice,\n",
    "            'learning_rate': current_lr,\n",
    "            'epoch_time': epoch_time,\n",
    "            'val_dice_change': val_dice - prev_val_dice,\n",
    "            'val_loss_change': val_loss - prev_val_loss,\n",
    "            'train_dice_change': train_dice - prev_train_dice,\n",
    "            'validation_type': \"Patch-Based\"\n",
    "        }\n",
    "        \n",
    "        training_metrics['epochs'].append(epoch_metrics)\n",
    "        \n",
    "        # Save checkpoint every 5 epochs\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            save_checkpoint(epoch + 1, model, optimizer, scheduler, best_dice, metrics_file)\n",
    "        \n",
    "        # Check for improvement\n",
    "        if val_dice > best_dice:\n",
    "            best_dice = val_dice\n",
    "            patience_counter = 0\n",
    "            \n",
    "            models_dir = config.get_path('saved_models_3d')\n",
    "            best_model_path = models_dir / f\"best_3d_unet_dice_{val_dice:.4f}.pth\"\n",
    "            \n",
    "            torch.save({\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_dice': best_dice,\n",
    "                'training_metrics': training_metrics\n",
    "            }, best_model_path)\n",
    "            \n",
    "            with open(metrics_file, 'w') as f:\n",
    "                json.dump(training_metrics, f, indent=2)\n",
    "            \n",
    "            logger.info(f\"Best model: Dice {best_dice:.4f} at epoch {epoch+1}\")\n",
    "            \n",
    "            if best_dice >= config.SKIP_THRESHOLD:\n",
    "                logger.info(f\"Target achieved: {config.SKIP_THRESHOLD:.1%} Dice\")\n",
    "                break\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        # Early stopping\n",
    "        if patience_counter >= config.TRAINING['PATIENCE']:\n",
    "            logger.info(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "        \n",
    "        # Update previous metrics\n",
    "        prev_val_dice = val_dice\n",
    "        prev_val_loss = val_loss\n",
    "        prev_train_dice = train_dice\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    # Final metrics save\n",
    "    training_metrics['end_time'] = datetime.now().isoformat()\n",
    "    training_metrics['best_dice'] = best_dice\n",
    "    training_metrics['total_epochs'] = len(training_metrics['epochs'])\n",
    "    \n",
    "    with open(metrics_file, 'w') as f:\n",
    "        json.dump(training_metrics, f, indent=2)\n",
    "    \n",
    "    return True, best_model_path, best_dice\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Execute the complete pipeline with dynamic path detection\"\"\"\n",
    "    logger.info(\"Starting 3D Stroke Segmentation Pipeline with Dynamic Paths\")\n",
    "    \n",
    "    # Display dataset info ONCE at startup\n",
    "    config.display_paths()\n",
    "    \n",
    "    # Verify dataset is accessible\n",
    "    if not config._validate_isles_path(config.ISLES_PATH):\n",
    "        logger.error(\"ISLES dataset not found or invalid!\")\n",
    "        logger.error(\"Please ensure ISLES-2022 dataset is available in one of the searched locations\")\n",
    "        return False\n",
    "    \n",
    "    # Stage 1: Preprocessing (Skip if exists)\n",
    "    if not run_stage_1_preprocessing():\n",
    "        logger.error(\"Stage 1 failed\")\n",
    "        return False\n",
    "    \n",
    "    # Stage 2: Advanced Alignment (Skip if exists)  \n",
    "    if not process_all_patients_aligned():\n",
    "        logger.error(\"Stage 2 failed\")\n",
    "        return False\n",
    "    \n",
    "    # Stage 3: Training Data Export (Skip if exists)\n",
    "    if not run_stage_3_export():\n",
    "        logger.error(\"Stage 3 failed\")\n",
    "        return False\n",
    "    \n",
    "    # Stage 4: Training (Skip if high-performance model exists)\n",
    "    training_skipped = run_stage_4_training()\n",
    "    if training_skipped:\n",
    "        logger.info(\"High-performance model already exists - skipping training\")\n",
    "    else:\n",
    "        logger.info(\"Starting training pipeline...\")\n",
    "        success, model_path, dice_score = run_training_pipeline()\n",
    "        \n",
    "        if success:\n",
    "            logger.info(f\"Training completed successfully - Best Dice: {dice_score:.4f}\")\n",
    "        else:\n",
    "            logger.error(\"Training failed\")\n",
    "            return False\n",
    "    \n",
    "    # Stage 5: Clinical Inference (Execute if trained model exists)\n",
    "    base_path = config.BASE_PATH\n",
    "    saved_models_dir = base_path / 'saved_models_3d'\n",
    "    model_files = list(saved_models_dir.glob(\"best_3d_unet_*_dice_*.pth\"))\n",
    "    static_model = saved_models_dir / 'best_model_3d_2.pth'\n",
    "\n",
    "    if model_files or static_model.exists():\n",
    "        if torch.cuda.is_available():\n",
    "            gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "            gpu_name = torch.cuda.get_device_name(0)\n",
    "            logger.info(f\"2-Modality inference ready on {gpu_name} ({gpu_memory_gb:.1f}GB)\")\n",
    "        else:\n",
    "            logger.error(\"GPU required for inference\")\n",
    "            return False\n",
    "            \n",
    "        logger.info(\"Starting clinical inference...\")\n",
    "        clinical_results = run_clinical_inference(resume=True)\n",
    "        \n",
    "        if clinical_results:\n",
    "            logger.info(f\"Clinical inference completed successfully\")\n",
    "        else:\n",
    "            logger.warning(\"Clinical inference returned no results\")\n",
    "    else:\n",
    "        logger.error(\"No trained model found - cannot run inference\")\n",
    "        return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd0e491",
   "metadata": {
    "title": "Cell 9: Execute Complete Pipeline"
   },
   "outputs": [],
   "source": [
    "# Clear GPU memory before starting\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "logger.info(\"=== STARTING COMPLETE 3D STROKE SEGMENTATION PIPELINE ===\")\n",
    "\n",
    "# Step 1: Run stages 1-3 (preprocessing, alignment, export) \n",
    "config.display_paths()\n",
    "\n",
    "if not config._validate_isles_path(config.ISLES_PATH):\n",
    "    logger.error(\"ISLES dataset not found or invalid!\")\n",
    "else:\n",
    "    # Stage 1: Preprocessing (Skip if exists)\n",
    "    if not run_stage_1_preprocessing():\n",
    "        logger.error(\"Stage 1 failed\")\n",
    "    else:\n",
    "        # Stage 2: Advanced Alignment (Skip if exists)  \n",
    "        if not process_all_patients_aligned():\n",
    "            logger.error(\"Stage 2 failed\")\n",
    "        else:\n",
    "            # Stage 3: Training Data Export (Skip if exists)\n",
    "            if not run_stage_3_export():\n",
    "                logger.error(\"Stage 3 failed\")\n",
    "            else:\n",
    "                # Step 2: Transfer DL folders to Colab (WAIT for completion)\n",
    "                logger.info(\"=== STEP 2: TRANSFERRING DL FOLDERS ===\")\n",
    "                transfer_dl_folders_to_colab()\n",
    "                \n",
    "                # Step 3: Start training (AFTER transfer completes)\n",
    "                logger.info(\"=== STEP 3: STARTING TRAINING ===\")\n",
    "                training_success = run_training_if_needed()\n",
    "                \n",
    "                if training_success:\n",
    "                    # Step 4: Run inference\n",
    "                    logger.info(\"=== STEP 4: STARTING INFERENCE ===\")\n",
    "                    base_path = config.BASE_PATH\n",
    "                    saved_models_dir = base_path / 'saved_models_3d'\n",
    "                    model_files = list(saved_models_dir.glob(\"best_3d_unet_*_dice_*.pth\"))\n",
    "                    static_model = saved_models_dir / 'best_model_3d_2.pth'\n",
    "\n",
    "                    if model_files or static_model.exists():\n",
    "                        if torch.cuda.is_available():\n",
    "                            gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "                            gpu_name = torch.cuda.get_device_name(0)\n",
    "                            logger.info(f\"2-Modality inference ready on {gpu_name} ({gpu_memory_gb:.1f}GB)\")\n",
    "                            \n",
    "                            clinical_results = run_clinical_inference(resume=True)\n",
    "                            \n",
    "                            if clinical_results:\n",
    "                                logger.info(f\"Clinical inference completed successfully\")\n",
    "                            else:\n",
    "                                logger.warning(\"Clinical inference returned no results\")\n",
    "                        else:\n",
    "                            logger.error(\"GPU required for inference\")\n",
    "                    else:\n",
    "                        logger.error(\"No trained model found - cannot run inference\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
